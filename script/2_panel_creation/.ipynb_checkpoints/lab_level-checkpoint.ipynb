{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84363f9f-70fb-48fb-b206-d493b36118f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raphael.wargon\\Documents\\GitHub\\sorting_univ\\script/headers/\n",
      "initalizing spark nlp session w gpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "base_path = os.path.dirname(os.path.abspath(\"\"))\n",
    "base_path = base_path + \"/headers/\"\n",
    "print(base_path)\n",
    "header_path = base_path + 'header_data_treatment.ipynb'\n",
    "%run $header_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4281833-6e5c-448a-9328-7a2a524cfdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_save_path = save_path + 'int_data_lab\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4a02ccc-98c7-4f2a-ab12-01d2a58ab37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\panel_fr_res\\\\int_data_lab\\\\'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_save_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3447ee1-08e3-4599-a342-3fbff4caaf60",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7ad5140-42b2-4622-8875-386419f58f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "works_au_af = (spark.read.format('parquet').load('file:\\\\' + main_path_openalex + 'works_au_af.parquet')\n",
    "               .filter( func.col('publication_year').between(1950,2020) )\n",
    "               .select('work_id','publication_year','author_id','source_id','citations','primary_topic')\n",
    "\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "511de567-f9aa-4279-882d-f81c1a1c4132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+-----------+--------------------+------------------+\n",
      "|  source_id|year|source_type|     rank_source_pct|   abs_rank_source|\n",
      "+-----------+----+-----------+--------------------+------------------+\n",
      "| S100014387|2014|    journal|  0.9673077009503904| 407.3062015503876|\n",
      "| S100016587|1997|    journal|  0.6246648793565683|            1379.0|\n",
      "|S1000263748|2012|    journal|  0.8371196475285695|            2343.0|\n",
      "| S100028386|1995|    journal|  0.7268862911795961|             256.0|\n",
      "| S100045985|1972|    journal|  0.8776194467728415|             146.0|\n",
      "| S100062655|2021|    journal|                 0.0|               1.0|\n",
      "|S1000839972|2015|    journal|  0.8853067047075607|             401.0|\n",
      "|S1000944648|2012|    journal|  0.4543330087633885|            2603.0|\n",
      "| S100105777|1991|    journal|  0.5352664576802508|             549.0|\n",
      "| S100105777|2010|    journal| 0.48626549156502025| 4091.909090909091|\n",
      "|S1001192252|2011|    journal|0.030941856511390683|            5374.0|\n",
      "|  S10012645|2018|    journal|  0.9472974996256924|             704.0|\n",
      "| S100126920|2016|    journal|  0.7600129407958589|            3701.0|\n",
      "| S100134864|1985|    journal|  0.2925413130861992|            1491.0|\n",
      "| S100134864|2008|    journal|  0.9796550440238073|134.44897959183672|\n",
      "| S100140721|2013|    journal|  0.7984624090435979|1164.3703703703702|\n",
      "| S100141054|2006|    journal| 0.25001966753845034| 4443.333333333333|\n",
      "| S100141487|1973|    journal| 0.29298321839505487|             512.5|\n",
      "| S100141487|1983|    journal|  0.5727411944869831|             269.0|\n",
      "| S100141487|2003|    journal|  0.8322158177404422| 797.7058823529412|\n",
      "+-----------+----+-----------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "journals_ranking = (spark.read.format('parquet').load('file:\\\\' + main_path_openalex + 'journals_ranking_year.parquet')\n",
    "                    .withColumn('source_id', func.regexp_replace(func.col('source_id'), 'https://openalex.org/', ''))\n",
    "                   )\n",
    "journals_ranking.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56fb185-612d-4b7c-b43c-5ab684b427a5",
   "metadata": {},
   "source": [
    "# Build the raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac80c8ef-50c3-420c-9c3c-4f5417fbc838",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "recoding= {   'I118618916'  :  \"I899635006\",\n",
    "              \"I36085230\"   :  \"I899635006\",\n",
    "              \"I177483745\"  :  \"I899635006\",\n",
    "              \"I4210103002\" :  \"I198244214\",\n",
    "              \"I4210143836\" :  \"I198244214\",\n",
    "              \"I184646667\"  :  \"I39804081\",\n",
    "              \"I102197404\"  :  \"I277688954\",\n",
    "              'I7171862'    :  \"I2279609970\",\n",
    "              \"I59807433\"   :  \"I2279609970\",\n",
    "              \"I2800379142\" :  \"I4210154111\",\n",
    "              \"I3123023596\" : \"I56067802\",\n",
    "              \"I4210095130\" : \"I208215962\" \n",
    "          #  , \"I4210140029\": \"I197518295\"\n",
    "}\n",
    "recoding = spark.sparkContext.broadcast(recoding)\n",
    "def recoding_univ(x):\n",
    "    if x in list(recoding.keys()):\n",
    "        return(recoding[x])\n",
    "    else:\n",
    "        return x\n",
    "udf_recoding_univ = func.udf(recoding_univ, StringType())\n",
    "list_fused = [\"I21491767\",\"I198244214\",\"I4210142324\",\n",
    "                \"I899635006\",\"I899635006\",\"I39804081\",\n",
    "                \"I201841394\",\"I4210154111\",\"I204730241\",\"I15057530\",\n",
    "                \"I277688954\",\"I68947357\",\"I2279609970\",\"I19894307\"]\n",
    "list_non_fr_non_uni_pub = ['I3131573726','I4210086079',\n",
    "                             \"I24240610\",\"I16465266\",'I35298706',\n",
    "                             \"I4210134562\",\"I185839726\",\"I4210143169\",\n",
    "                             \"I4210127465\",\"I10342815\",\n",
    "                             \"I57206974\",\"I193291145\",\"I4210163862\",\"I124357947\",\n",
    "                             \"I97565354\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da92523e-e991-4553-804b-1f4c608a8d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "inst = spark.read.parquet('file:\\\\' + save_path + 'inst_fr.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "946af1eb-106f-42e5-9d7b-f855f90dceb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "au_inst_level_flow = (works_au_af\n",
    "                      .join(journals_ranking.withColumnRenamed('year','publication_year'), on = ['source_id','publication_year'], how = 'left')\n",
    "                      .withColumn('inst_id', func.when(func.col('inst_id')=='I118618916',  \"I899635006\")\n",
    "                                                 .when(func.col('inst_id')==\"I36085230\",  \"I899635006\")\n",
    "                                                 .when(func.col('inst_id')==\"I177483745\",  \"I899635006\")\n",
    "                                                 .when(func.col('inst_id')==\"I4210103002\", \"I198244214\")\n",
    "                                                 .when(func.col('inst_id')==\"I4210143836\", \"I198244214\")\n",
    "                                                 .when(func.col('inst_id')==\"I184646667\",  \"I39804081\")\n",
    "                                                 .when(func.col('inst_id')==\"I102197404\",  \"I277688954\")\n",
    "                                                 .when(func.col('inst_id')=='I7171862',  \"I2279609970\")\n",
    "                                                 .when(func.col('inst_id')==\"I59807433\",  \"I2279609970\")\n",
    "                                                 .when(func.col('inst_id')==\"I2800379142\", \"I4210154111\") \n",
    "                                                 .when(func.col('inst_id')==\"I3123023596\",\"I56067802\")\n",
    "                                                 .when(func.col('inst_id')==\"I4210095130\",\"I208215962\")\n",
    "                                                 .otherwise(func.col('inst_id')))\n",
    "                      .filter(func.col('inst_id').isNotNull())\n",
    "                      .join(inst.select('inst_id', func.lit(1).alias('in_inst_dataset')), on =['inst_id'], how = 'left')\n",
    "                      .fillna(0, subset = ['in_inst_dataset'])\n",
    "                    .withColumn('inst_id', func.when( (func.col('country')==\"FR\")\n",
    "                                                     | (func.col('in_inst_dataset') ==1)\n",
    "                                                     , func.col('inst_id')).otherwise('abroad'))\n",
    "                      \n",
    "                    .groupBy('author_id',func.col('publication_year').alias('year'),'work_id')\n",
    "                    .agg(func.collect_set('inst_id').alias('inst_id_set_y'),\n",
    "                         *[func.first(col).alias(col) for col in ['citations', 'rank_source_pct']]\n",
    "                        )\n",
    "                      .withColumn('coau_set', func.collect_set(func.col('author_id')).over(Window.partitionBy('work_id')))\n",
    "                    .groupBy('author_id','year')\n",
    "                    .agg(func.array_compact(func.flatten(func.collect_set('inst_id_set_y'))).alias('inst_id_set_y'),\n",
    "                         func.array_compact(func.flatten(func.collect_set('coau_set'))).alias('coau_set'),\n",
    "                         func.countDistinct('work_id').alias('publications'),\n",
    "                         func.sum('citations').alias('citations'),\n",
    "                         func.mean('rank_source_pct').alias('avg_rank_source_pct'), \n",
    "                         func.sum('rank_source_pct').alias('rank_w_publications'),\n",
    "                         func.sum((func.col('rank_source_pct')<= 0.5).cast('int')).alias('nr_source_btm_50pct_raw'),\n",
    "                         func.sum((func.col('rank_source_pct').between(0.5,0.9)).cast('int')).alias('nr_source_mid_40pct_raw'),\n",
    "                         func.sum((func.col('rank_source_pct')>= 0.8).cast('int')).alias('nr_source_top_20pct_raw'),\n",
    "                         func.sum((func.col('rank_source_pct')>= 0.9).cast('int')).alias('nr_source_top_10pct_raw'),\n",
    "                         func.sum((func.col('rank_source_pct')>= 0.95).cast('int')).alias('nr_source_top_5pct_raw'),\n",
    "                        )\n",
    "\n",
    "                    #.withColumn('inst_id_set_last_y', func.lag(func.col('inst_id_set_y')).over(Window.partitionBy('author_id').orderBy('year')))\n",
    "                    #.withColumn('inst_id_receiver', func.explode(func.col('inst_id_set_y')))\n",
    "                    #.withColumn('inst_id_sender',  func.explode_outer(func.col('inst_id_set_last_y')))\n",
    "                    #.select('inst_id_receiver','inst_id_sender', 'author_id','year')\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f648b4f-f66e-48d8-b36a-4ba2d3fa0110",
   "metadata": {},
   "outputs": [],
   "source": [
    "au_inst_level_flow.write.mode('overwrite').parquet('file:\\\\' + save_path + 'au_inst_level.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88759806-fd59-4701-9e6c-0a95dd55ff27",
   "metadata": {},
   "source": [
    "# Add inst-level info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "909c76ae-5c49-40a9-86f9-27309e77bf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "au_inst_level_flow = spark.read.parquet('file:\\\\' + save_path + 'au_inst_level.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4fce616-6cd5-41cc-bd26-67ea689a9c1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- inst_id_receiver: string (nullable = true)\n",
      " |-- inst_id_sender: string (nullable = true)\n",
      " |-- author_id: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "au_inst_level_flow = (au_inst_level_flow\n",
    "                    .withColumn('inst_id_set_last_y', func.lag(func.col('inst_id_set_y')).over(Window.partitionBy('author_id').orderBy('year')))\n",
    "                    .withColumn('inst_id_receiver', func.explode(func.col('inst_id_set_y')))\n",
    "                    .withColumn('inst_id_sender',  func.explode_outer(func.col('inst_id_set_last_y')))\n",
    "                    .select('inst_id_receiver','inst_id_sender', 'author_id','year')\n",
    "                    .distinct()\n",
    "\n",
    "                     )\n",
    "au_inst_level_flow.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc9d64d2-ab4b-4e10-a8ca-4f7f4925b14a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o204.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 7.0 failed 1 times, most recent failure: Lost task 0.0 in stage 7.0 (TID 405) (localhost executor driver): java.lang.OutOfMemoryError: Java heap space\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\nCaused by: java.lang.OutOfMemoryError: Java heap space\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m au_inst_level_flow\u001b[38;5;241m.\u001b[39mcache()\n\u001b[1;32m----> 2\u001b[0m au_inst_level_flow\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyspark\\sql\\dataframe.py:945\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    885\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow\u001b[39m(\u001b[38;5;28mself\u001b[39m, n: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, truncate: Union[\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, vertical: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    886\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Prints the first ``n`` rows to the console.\u001b[39;00m\n\u001b[0;32m    887\u001b[0m \n\u001b[0;32m    888\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    943\u001b[0m \u001b[38;5;124;03m    name | Bob\u001b[39;00m\n\u001b[0;32m    944\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 945\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_show_string(n, truncate, vertical))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyspark\\sql\\dataframe.py:963\u001b[0m, in \u001b[0;36mDataFrame._show_string\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    957\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[0;32m    958\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    959\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(vertical)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[0;32m    960\u001b[0m     )\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[1;32m--> 963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mshowString(n, \u001b[38;5;241m20\u001b[39m, vertical)\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    965\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[0;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o204.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 7.0 failed 1 times, most recent failure: Lost task 0.0 in stage 7.0 (TID 405) (localhost executor driver): java.lang.OutOfMemoryError: Java heap space\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\nCaused by: java.lang.OutOfMemoryError: Java heap space\r\n"
     ]
    }
   ],
   "source": [
    "au_inst_level_flow.cache()\n",
    "au_inst_level_flow.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8ae12b-acbf-4f01-a954-bec272ca9a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "au_inst_level_flow.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef35f60-19c5-4efb-a123-c8e3cb610f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "au_inst_level_flow.filter( ~ ( \n",
    "                                    (func.col('inst_id_sender').isin(['abroad']))\n",
    "                                    &  (func.col('inst_id_receiver').isin(['abroad']))\n",
    "                                )).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9de1381-93f8-4384-9eb3-335d3243c731",
   "metadata": {},
   "outputs": [],
   "source": [
    "au_inst_level_flow_filtering = (au_inst_level_flow\n",
    "                                .filter( ~ ( \n",
    "                                    (func.col('inst_id_sender').isin(['abroad']))\n",
    "                                    &  (func.col('inst_id_receiver').isin(['abroad']))\n",
    "                                ))\n",
    "                                .join(inst\n",
    "                                        .select(func.col('inst_id').alias('inst_id_receiver'), \n",
    "                                                func.col('parent.parent_id').alias('parent_id_r'))\n",
    "                                        , on = 'inst_id_receiver', how ='left')\n",
    "                                .join(inst\n",
    "                                        .select(func.col('inst_id').alias('inst_id_sender'), \n",
    "                                                func.col('parent.parent_id').alias('parent_id_s'))\n",
    "                                        , on = 'inst_id_sender', how ='left')\n",
    "            \n",
    "                                .withColumn('parent_id_r', func.array_except(func.col('parent_id_r'), func.array(func.col('inst_id_receiver'))))\n",
    "                                .withColumn('parent_id_s', func.array_except(func.col('parent_id_s'), func.array(func.col('inst_id_sender'))))\n",
    "                                .groupBy('author_id','year')\n",
    "                                .agg(func.collect_set(func.col('inst_id_receiver')).alias('inst_id_receiver'),\n",
    "                                     func.collect_set(func.col('inst_id_sender')).alias('inst_id_sender'),\n",
    "                                     func.array_except(func.transform(func.array_distinct(func.flatten(func.collect_set(func.col('parent_id_r')))), lambda x: func.regexp_replace(x, 'https://openalex.org/', ''))\n",
    "                                                                                 , func.array(func.lit(None))).alias('all_parent_ids_r'),\n",
    "                                     \n",
    "                                     func.array_except(func.transform(func.array_distinct(func.flatten(func.collect_set(func.col('parent_id_s')))), lambda x: func.regexp_replace(x, 'https://openalex.org/', ''))\n",
    "                                                                                 , func.array(func.lit(None))).alias('all_parent_ids_s')\n",
    "                               )\n",
    "                                .withColumn('inst_id_receiver', func.explode(func.array_except(func.col('inst_id_receiver'), func.col('all_parent_ids_r'))))\n",
    "                                .withColumn('inst_set_sender', func.col('inst_id_sender'))\n",
    "                                .withColumn('inst_id_sender',   func.explode_outer(func.array_except(func.col('inst_id_sender'), func.col('all_parent_ids_s'))))\n",
    "\n",
    "                                .select('inst_id_receiver','inst_id_sender', 'inst_set_sender', 'author_id','year')\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9ed63e0-3785-433e-a1e3-31668bac0ef2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o301.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 10.0 failed 1 times, most recent failure: Lost task 3.0 in stage 10.0 (TID 417) (localhost executor driver): java.lang.OutOfMemoryError: Java heap space\r\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillReader.<init>(UnsafeSorterSpillReader.java:50)\r\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillWriter.getReader(UnsafeSorterSpillWriter.java:159)\r\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.getSortedIterator(UnsafeExternalSorter.java:555)\r\n\tat org.apache.spark.sql.execution.UnsafeExternalRowSorter.sort(UnsafeExternalRowSorter.java:172)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage4.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anon$1.fetchNextRow(WindowExec.scala:118)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anon$1.<init>(WindowExec.scala:127)\r\n\tat org.apache.spark.sql.execution.window.WindowExec.$anonfun$doExecute$3(WindowExec.scala:107)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$Lambda/0x0000023d021ac000.apply(Unknown Source)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:855)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:855)\r\n\tat org.apache.spark.rdd.RDD$$Lambda/0x0000023d0191b930.apply(Unknown Source)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\nCaused by: java.lang.OutOfMemoryError: Java heap space\r\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillReader.<init>(UnsafeSorterSpillReader.java:50)\r\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillWriter.getReader(UnsafeSorterSpillWriter.java:159)\r\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.getSortedIterator(UnsafeExternalSorter.java:555)\r\n\tat org.apache.spark.sql.execution.UnsafeExternalRowSorter.sort(UnsafeExternalRowSorter.java:172)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage4.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anon$1.fetchNextRow(WindowExec.scala:118)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anon$1.<init>(WindowExec.scala:127)\r\n\tat org.apache.spark.sql.execution.window.WindowExec.$anonfun$doExecute$3(WindowExec.scala:107)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$Lambda/0x0000023d021ac000.apply(Unknown Source)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:855)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:855)\r\n\tat org.apache.spark.rdd.RDD$$Lambda/0x0000023d0191b930.apply(Unknown Source)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m au_inst_level_flow_filtering\u001b[38;5;241m.\u001b[39mcache()\n\u001b[1;32m----> 2\u001b[0m au_inst_level_flow_filtering\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyspark\\sql\\dataframe.py:945\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    885\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow\u001b[39m(\u001b[38;5;28mself\u001b[39m, n: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, truncate: Union[\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, vertical: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    886\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Prints the first ``n`` rows to the console.\u001b[39;00m\n\u001b[0;32m    887\u001b[0m \n\u001b[0;32m    888\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    943\u001b[0m \u001b[38;5;124;03m    name | Bob\u001b[39;00m\n\u001b[0;32m    944\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 945\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_show_string(n, truncate, vertical))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyspark\\sql\\dataframe.py:963\u001b[0m, in \u001b[0;36mDataFrame._show_string\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    957\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[0;32m    958\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    959\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(vertical)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[0;32m    960\u001b[0m     )\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[1;32m--> 963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mshowString(n, \u001b[38;5;241m20\u001b[39m, vertical)\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    965\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[0;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o301.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 10.0 failed 1 times, most recent failure: Lost task 3.0 in stage 10.0 (TID 417) (localhost executor driver): java.lang.OutOfMemoryError: Java heap space\r\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillReader.<init>(UnsafeSorterSpillReader.java:50)\r\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillWriter.getReader(UnsafeSorterSpillWriter.java:159)\r\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.getSortedIterator(UnsafeExternalSorter.java:555)\r\n\tat org.apache.spark.sql.execution.UnsafeExternalRowSorter.sort(UnsafeExternalRowSorter.java:172)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage4.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anon$1.fetchNextRow(WindowExec.scala:118)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anon$1.<init>(WindowExec.scala:127)\r\n\tat org.apache.spark.sql.execution.window.WindowExec.$anonfun$doExecute$3(WindowExec.scala:107)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$Lambda/0x0000023d021ac000.apply(Unknown Source)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:855)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:855)\r\n\tat org.apache.spark.rdd.RDD$$Lambda/0x0000023d0191b930.apply(Unknown Source)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\nCaused by: java.lang.OutOfMemoryError: Java heap space\r\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillReader.<init>(UnsafeSorterSpillReader.java:50)\r\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillWriter.getReader(UnsafeSorterSpillWriter.java:159)\r\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.getSortedIterator(UnsafeExternalSorter.java:555)\r\n\tat org.apache.spark.sql.execution.UnsafeExternalRowSorter.sort(UnsafeExternalRowSorter.java:172)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage4.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anon$1.fetchNextRow(WindowExec.scala:118)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anon$1.<init>(WindowExec.scala:127)\r\n\tat org.apache.spark.sql.execution.window.WindowExec.$anonfun$doExecute$3(WindowExec.scala:107)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$Lambda/0x0000023d021ac000.apply(Unknown Source)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:855)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:855)\r\n\tat org.apache.spark.rdd.RDD$$Lambda/0x0000023d0191b930.apply(Unknown Source)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n"
     ]
    }
   ],
   "source": [
    "au_inst_level_flow_filtering.cache()\n",
    "au_inst_level_flow_filtering.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d1a59e89-0d66-422e-99cb-a49e6d138d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19891277"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "au_inst_level_flow_filtering.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9012da0-6c0d-416e-acae-9cabca067449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2261482"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "au_inst_level_flow_filtering.filter(func.col('inst_id_receiver')==\"I1294671590\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ecd1ab7-02c2-4507-b807-e734705b6bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2863753"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "au_inst_level_flow.filter(func.col('inst_id_receiver')==\"I1294671590\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6a7dcc2-d830-4f99-a03b-5433af904c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[inst_id_receiver: string, inst_id_sender: string, inst_set_sender: array<string>, author_id: string, year: int]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "au_inst_level_flow.repartition('year')\n",
    "au_inst_level_flow_filtering.repartition('year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e9ad9c-6017-4004-bbd7-dff2ebe483e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weights_by_au_year = (au_inst_level_flow_filtering\n",
    "                      .groupBy('author_id','year')\n",
    "                      .count()\n",
    "                      .select('author_id','year', (1/func.col('count')).alias('weights'))\n",
    "                     )\n",
    "weights_by_au_year.cache()\n",
    "weights_by_au_year.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4673176-bc3a-41dd-8915-5779a577ba23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30301591"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "au_inst_level_flow.select('author_id').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8832851a-e93d-46c0-9332-d28ab9493426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1553692"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "au_inst_level_flow_filtering.select('author_id').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b86030a0-d3e8-44ff-9215-ed74ff235b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|  secteur|\n",
      "+---------+\n",
      "|   public|\n",
      "|    privé|\n",
      "|undefined|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inst.select('secteur').distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9cdee1-b77b-495e-8c52-917bffe48a8b",
   "metadata": {},
   "source": [
    "# author-level info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a187e4e1-ca7c-43d8-b571-654aadc4ab3b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'au_inst_level_flow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m au_level_info \u001b[38;5;241m=\u001b[39m (au_inst_level_flow\n\u001b[0;32m      2\u001b[0m                  \u001b[38;5;66;03m#.join(au_to_keep, on= 'author_id', how ='inner')\u001b[39;00m\n\u001b[0;32m      3\u001b[0m                  \u001b[38;5;241m.\u001b[39mgroupBy(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthor_id\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m                  \u001b[38;5;241m.\u001b[39magg(func\u001b[38;5;241m.\u001b[39mmin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentry_year\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      5\u001b[0m                       func\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexit_year\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      6\u001b[0m                  \u001b[38;5;241m.\u001b[39mjoin(au_inst_level_flow\n\u001b[0;32m      7\u001b[0m                        \u001b[38;5;241m.\u001b[39mgroupBy(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthor_id\u001b[39m\u001b[38;5;124m'\u001b[39m, func\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentry_year\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      8\u001b[0m                        \u001b[38;5;241m.\u001b[39magg(func\u001b[38;5;241m.\u001b[39marray_sort(func\u001b[38;5;241m.\u001b[39mcollect_set(func\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minst_id_receiver\u001b[39m\u001b[38;5;124m'\u001b[39m)))\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentry_inst_id\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m                            )\n\u001b[0;32m     10\u001b[0m                        , on \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthor_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentry_year\u001b[39m\u001b[38;5;124m'\u001b[39m], how \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m                 )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'au_inst_level_flow' is not defined"
     ]
    }
   ],
   "source": [
    "au_level_info = (au_inst_level_flow\n",
    "                 #.join(au_to_keep, on= 'author_id', how ='inner')\n",
    "                 .groupBy('author_id')\n",
    "                 .agg(func.min('year').alias('entry_year'),\n",
    "                      func.max('year').alias('exit_year'))\n",
    "                 .join(au_inst_level_flow\n",
    "                       .groupBy('author_id', func.col('year').alias(\"entry_year\"))\n",
    "                       .agg(func.array_sort(func.collect_set(func.col('inst_id_receiver'))).alias('entry_inst_id')\n",
    "                           )\n",
    "                       , on = ['author_id', 'entry_year'], how = 'left')\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83889915-c61d-4bce-8522-c1f2b0b70724",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "au_level_info.write.mode('overwrite').parquet('file:\\\\' + save_path + 'au_level_for_inst_dataset.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac17fd3-e130-4e40-a760-f05654affc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "au_level_info = spark.read.parquet('file:\\\\' + save_path + 'au_level_for_inst_dataset.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01dad497-37ff-4975-aed9-7dfd01a6dbc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30301591"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "au_level_info.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9677b5-67c9-45cc-b49b-c3c4bb033e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "au_inst_level_plus_info = (au_inst_level_flow_filtering\n",
    "                           .join(au_level_info, on = ['author_id'], how =  'left'))\n",
    "au_inst_level_plus_info.cache()\n",
    "au_inst_level_plus_info.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbdc9f0-92a3-4448-a955-3d9f98e3f437",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "au_inst_level_plus_info.filter(func.col('author_id')==\"A5053834730\").filter(func.col('inst_id_sender')==\"I187986737\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13988aef-f73d-4cfc-b54e-46243d314a3c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# institution-to-institution-level raw flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "82cbfb3e-49b8-4eb7-8143-6fef58072852",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_inst_flow = (au_inst_level_plus_info\n",
    "                    .filter(func.col('year').between(1980,2020))\n",
    "                  .withColumn('stayer', func.array_contains(func.col('inst_set_sender'), func.col('inst_id_receiver')).cast('int'))\n",
    "\n",
    "                  .withColumn('junior', (func.col('year')-func.col('entry_year')<=5).cast('int'))\n",
    "                  .withColumn('senior', (func.col('year')-func.col('entry_year')>=15).cast('int'))\n",
    "                  .withColumn('medium', ((func.col('year')-func.col('entry_year')>5) & (func.col('year')-func.col('entry_year')<15)) .cast('int'))\n",
    "\n",
    "                  .withColumn('own_entrant_r', (func.array_contains(func.col('entry_inst_id'), func.col('inst_id_receiver')) ).cast('int'))\n",
    "                  .withColumn('own_entrant_s', (func.array_contains(func.col('entry_inst_id'), func.col('inst_id_sender')) ).cast('int'))\n",
    "\n",
    "                  .withColumn('foreign_entrant', (func.array_contains(func.col('entry_inst_id'),('abroad')) ).cast('int'))\n",
    "                 .join(weights_by_au_year, on = ['author_id','year'], how = 'left')\n",
    "                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a25c93c1-d9a7-41e7-b92c-a62ecc8b47a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+----------------+--------------+--------------------+----------+---------+--------------------+------+------+------+------+-------------+-------------+---------------+-------+\n",
      "|  author_id|year|inst_id_receiver|inst_id_sender|     inst_set_sender|entry_year|exit_year|       entry_inst_id|stayer|junior|senior|medium|own_entrant_r|own_entrant_s|foreign_entrant|weights|\n",
      "+-----------+----+----------------+--------------+--------------------+----------+---------+--------------------+------+------+------+------+-------------+-------------+---------------+-------+\n",
      "|A5000220048|2001|      I187986737|    I187986737|        [I187986737]|      1999|     2009|        [I187986737]|     1|     1|     0|     0|            1|            1|              0|    1.0|\n",
      "|A5000524924|1999|     I4210141964|    I187986737|[I4210121705, I15...|      1981|     2019|        [I154526488]|     1|     0|     1|     0|            0|            0|              0|    0.2|\n",
      "|A5000574183|1997|     I4210096867|    I187986737|[I1294671590, I18...|      1992|     2020|            [abroad]|     0|     1|     0|     0|            0|            0|              1|  0.125|\n",
      "|A5000574183|1997|          abroad|    I187986737|[I1294671590, I18...|      1992|     2020|            [abroad]|     0|     1|     0|     0|            1|            0|              1|  0.125|\n",
      "|A5000574183|1997|      I187986737|    I187986737|[I1294671590, I18...|      1992|     2020|            [abroad]|     1|     1|     0|     0|            0|            0|              1|  0.125|\n",
      "|A5000574183|1997|     I1294671590|    I187986737|[I1294671590, I18...|      1992|     2020|            [abroad]|     1|     1|     0|     0|            0|            0|              1|  0.125|\n",
      "|A5001284057|2002|          abroad|    I187986737|        [I187986737]|      1981|     2002|            [abroad]|     0|     0|     1|     0|            1|            0|              1|    1.0|\n",
      "|A5001402760|1985|      I187986737|    I187986737|        [I187986737]|      1984|     2020|        [I187986737]|     1|     1|     0|     0|            1|            1|              0|    1.0|\n",
      "|A5002033125|2009|          abroad|    I187986737|[I154526488, I187...|      2005|     2018|[I154526488, I187...|     0|     1|     0|     0|            0|            1|              0|    0.5|\n",
      "|A5002524980|1993|      I154526488|    I187986737|        [I187986737]|      1986|     2020|            [abroad]|     0|     0|     0|     1|            0|            0|              1|    0.5|\n",
      "|A5002524980|1993|      I187986737|    I187986737|        [I187986737]|      1986|     2020|            [abroad]|     1|     0|     0|     1|            0|            0|              1|    0.5|\n",
      "|A5002524980|1994|      I154526488|    I187986737|[I154526488, I187...|      1986|     2020|            [abroad]|     1|     0|     0|     1|            0|            0|              1|   0.25|\n",
      "|A5002524980|1994|      I187986737|    I187986737|[I154526488, I187...|      1986|     2020|            [abroad]|     1|     0|     0|     1|            0|            0|              1|   0.25|\n",
      "|A5002863646|1990|          abroad|    I187986737|[I187986737, I421...|      1976|     2020|            [abroad]|     0|     0|     0|     1|            1|            0|              1|    0.5|\n",
      "|A5003511265|2016|     I4210157221|    I187986737|[I1294671590, I18...|      2002|     2020|       [I4210119260]|     0|     0|     0|     1|            0|            0|              0|  0.125|\n",
      "|A5003511265|2016|          abroad|    I187986737|[I1294671590, I18...|      2002|     2020|       [I4210119260]|     1|     0|     0|     1|            0|            0|              0|  0.125|\n",
      "|A5003584081|1981|      I187986737|    I187986737|        [I187986737]|      1978|     1981|       [I4210121926]|     1|     1|     0|     0|            0|            0|              0|    0.5|\n",
      "|A5003584081|1981|     I4210140797|    I187986737|        [I187986737]|      1978|     1981|       [I4210121926]|     0|     1|     0|     0|            0|            0|              0|    0.5|\n",
      "|A5003709225|2002|      I154526488|    I187986737|[I154526488, I187...|      1989|     2007|[I154526488, I187...|     1|     0|     0|     1|            1|            1|              0|   0.25|\n",
      "|A5003709225|2002|      I187986737|    I187986737|[I154526488, I187...|      1989|     2007|[I154526488, I187...|     1|     0|     0|     1|            1|            1|              0|   0.25|\n",
      "+-----------+----+----------------+--------------+--------------------+----------+---------+--------------------+------+------+------+------+-------------+-------------+---------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pre_inst_flow.filter(func.col('inst_id_sender')==\"I187986737\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ce796e8d-1ba2-4766-a123-37ceb95168f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_level_flows = (pre_inst_flow\n",
    "                    .groupBy('inst_id_receiver','inst_id_sender', 'year')\n",
    "                      .agg(func.countDistinct('author_id').alias('total'),\n",
    "                           func.sum('stayer').alias('stayers'),\n",
    "                           func.sum(1-func.col('stayer')).alias('movers'),\n",
    "                        \n",
    "                           func.sum('weights').alias('total_w'),\n",
    "                           func.sum(func.col('weights')*func.col('stayer')).alias('stayers_w'),\n",
    "                           func.sum(func.col('weights')*(1-func.col('stayer'))).alias('movers_w'),\n",
    "\n",
    "\n",
    "                           *[func.sum(category).alias('total_' + category )\n",
    "                             for category in ['junior','senior','medium', 'own_entrant_r','own_entrant_s', 'foreign_entrant']\n",
    "                           ],\n",
    "\n",
    "                           *[func.sum(func.col('stayer')*func.col(category)).alias('stayers_' + category) for category in ['junior','senior','medium', 'own_entrant_r','own_entrant_s', 'foreign_entrant']\n",
    "                           ],\n",
    "\n",
    "                           *[func.sum( (1-func.col('stayer'))*func.col(category)).alias('movers_' + category) for category in ['junior','senior','medium', 'own_entrant_r','own_entrant_s', 'foreign_entrant']\n",
    "                           ],\n",
    "\n",
    "                        \n",
    "                           *[func.sum(func.col('weights')*func.col(category)).alias('total_w_' + category)for category in ['junior','senior','medium', 'own_entrant_r','own_entrant_s', 'foreign_entrant']\n",
    "                           ],\n",
    "                           *[func.sum(func.col('weights')*func.col('stayer')*func.col(category)).alias('stayers_w_' + category) for category in ['junior','senior','medium', 'own_entrant_r','own_entrant_s', 'foreign_entrant']\n",
    "                           ],\n",
    "                           *[func.sum(func.col('weights')*(1-func.col('stayer'))*func.col(category)).alias('movers_w_' + category) for category in ['junior','senior','medium', 'own_entrant_r','own_entrant_s', 'foreign_entrant']\n",
    "                           ],\n",
    "                           \n",
    "                           \n",
    "\n",
    "                          )\n",
    "                      .join(inst\n",
    "                            .select(func.col('inst_id').alias('inst_id_receiver'), \n",
    "                                  *[func.col(col).alias(col +'_r') for col in ['name','city','parent','fused','uni_pub','cnrs','type','main_topic','idex','type_fr','secteur']],\n",
    "                                   func.concat_ws(';', func.transform(func.col('topic_share'), lambda x: func.to_json(x))).alias('topic_share_r'),\n",
    "                                   *[ (func.col('type_fr') == type_).cast('int').alias(type_.lower().replace('é', 'e') +'_r')\n",
    "                                         for type_ in ['Université', 'École']],\n",
    "                                    *[(func.col('secteur') == type_).cast('int').alias(type_.lower().replace('é', 'e') +'_r')\n",
    "                                     for type_ in ['public', 'privé']]\n",
    "                                   )\n",
    "                            , on = 'inst_id_receiver', how ='left')\n",
    "                      .join(inst\n",
    "                            .select(func.col('inst_id').alias('inst_id_sender'), \n",
    "                                    *[func.col(col).alias(col +'_s') for col in ['name','city','parent','fused','uni_pub','cnrs','type','main_topic','idex','type_fr','secteur']],\n",
    "                                   func.concat_ws(';', func.transform(func.col('topic_share'), lambda x: func.to_json(x))).alias('topic_share_s'),\n",
    "                                   *[ (func.col('type_fr') == type_).cast('int').alias(type_.lower().replace('é', 'e') +'_s')\n",
    "                                         for type_ in ['Université', 'École']],\n",
    "                                    *[(func.col('secteur') == type_).cast('int').alias(type_.lower().replace('é', 'e') +'_s')\n",
    "                                     for type_ in ['public', 'privé']]\n",
    "                                   )\n",
    "                            , on = 'inst_id_sender', how ='left')\n",
    "\n",
    "                    .withColumn('type_r', func.when(func.col('inst_id_receiver')==\"abroad\", 'abroad').otherwise(func.col('type_r')))\n",
    "                    .withColumn('type_s', func.when(func.col('inst_id_sender')==\"abroad\", 'abroad').otherwise(func.col('type_s')))\n",
    "                    .fillna(0, subset = ['fused_r','fused_s','uni_pub_r','uni_pub_s','cnrs_r','cnrs_s','universite_s','universite_r','ecole_r','ecole_s', 'prive_s','prive_r', 'public_s','public_r'] )\n",
    "                    \n",
    "                    #.withColumn('size_r', func.max(func.col('stayers') * (func.col('inst_id_receiver')==func.col('inst_id_sender')).cast('int'))\n",
    "                    #\n",
    "                    #            .over(Window.partitionBy('inst_id_receiver','year')))\n",
    "                    #\n",
    "                    #.withColumn('size_s', func.max(func.col('stayers') * (func.col('inst_id_receiver')==func.col('inst_id_sender')).cast('int'))\n",
    "                    #                  .over(Window.partitionBy('inst_id_sender','year')))\n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb02cdf-ce6a-44a0-8ce1-f400e70c5072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1d7988de-1674-4adc-b25d-017c938e961a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------+----+-----+-------+------+-------------------+------------------+-------------------+------------+------------+------------+-------------------+-------------------+---------------------+--------------+--------------+--------------+---------------------+---------------------+-----------------------+-------------+-------------+-------------+--------------------+--------------------+----------------------+-------------------+-------------------+-------------------+---------------------+---------------------+-----------------------+-------------------+-------------------+-------------------+-----------------------+-----------------------+-------------------------+-------------------+-------------------+-------------------+----------------------+----------------------+------------------------+--------------------+--------------------+--------------------+-------+---------+------+----------+--------------------+--------------------+----------+---------+--------------------+------------+-------+--------+-------+--------------------+----------------+--------------------+-------+---------+------+----------+--------------------+--------------------+----------+---------+--------------------+------------+-------+--------+-------+\n",
      "|inst_id_sender|inst_id_receiver|year|total|stayers|movers|            total_w|         stayers_w|           movers_w|total_junior|total_senior|total_medium|total_own_entrant_r|total_own_entrant_s|total_foreign_entrant|stayers_junior|stayers_senior|stayers_medium|stayers_own_entrant_r|stayers_own_entrant_s|stayers_foreign_entrant|movers_junior|movers_senior|movers_medium|movers_own_entrant_r|movers_own_entrant_s|movers_foreign_entrant|     total_w_junior|     total_w_senior|     total_w_medium|total_w_own_entrant_r|total_w_own_entrant_s|total_w_foreign_entrant|   stayers_w_junior|   stayers_w_senior|   stayers_w_medium|stayers_w_own_entrant_r|stayers_w_own_entrant_s|stayers_w_foreign_entrant|    movers_w_junior|    movers_w_senior|    movers_w_medium|movers_w_own_entrant_r|movers_w_own_entrant_s|movers_w_foreign_entrant|              name_r|              city_r|            parent_r|fused_r|uni_pub_r|cnrs_r|    type_r|        main_topic_r|              idex_r| type_fr_r|secteur_r|       topic_share_r|universite_r|ecole_r|public_r|prive_r|              name_s|          city_s|            parent_s|fused_s|uni_pub_s|cnrs_s|    type_s|        main_topic_s|              idex_s| type_fr_s|secteur_s|       topic_share_s|universite_s|ecole_s|public_s|prive_s|\n",
      "+--------------+----------------+----+-----+-------+------+-------------------+------------------+-------------------+------------+------------+------------+-------------------+-------------------+---------------------+--------------+--------------+--------------+---------------------+---------------------+-----------------------+-------------+-------------+-------------+--------------------+--------------------+----------------------+-------------------+-------------------+-------------------+---------------------+---------------------+-----------------------+-------------------+-------------------+-------------------+-----------------------+-----------------------+-------------------------+-------------------+-------------------+-------------------+----------------------+----------------------+------------------------+--------------------+--------------------+--------------------+-------+---------+------+----------+--------------------+--------------------+----------+---------+--------------------+------------+-------+--------+-------+--------------------+----------------+--------------------+-------+---------+------+----------+--------------------+--------------------+----------+---------+--------------------+------------+-------+--------+-------+\n",
      "|        abroad|     I4210146969|2020|    7|      3|     4| 1.5583333333333333|0.3472222222222222| 1.2111111111111112|           1|           3|           3|                  1|                  4|                    4|             1|             1|             1|                    1|                    2|                      2|            0|            2|            2|                   0|                   2|                     2| 0.1111111111111111|              0.725| 0.7222222222222222|   0.1111111111111111|   0.8472222222222222|     0.8472222222222222| 0.1111111111111111|              0.125| 0.1111111111111111|     0.1111111111111111|     0.2361111111111111|       0.2361111111111111|                0.0|                0.6| 0.6111111111111112|                   0.0|    0.6111111111111112|      0.6111111111111112|Laboratoire de Bi...|            Toulouse|[{I4210096427, In...|      0|        1|     1|  facility|Biochemistry, Gen...|idex_annulee_toul...|Université|   public|{\"field\":\"Biochem...|           1|      0|       1|      0|                NULL|            NULL|                NULL|      0|        0|     0|    abroad|                NULL|                NULL|      NULL|     NULL|                NULL|           0|      0|       0|      0|\n",
      "|   I2738703131|     I2738703131|1998|  798|    798|     0| 224.76944113756613|224.76944113756613|                0.0|         240|         313|         245|                309|                309|                  174|           240|           313|           245|                  309|                  309|                    174|            0|            0|            0|                   0|                   0|                     0|  85.53083333333336|  69.81983796296296|  69.41876984126982|   121.31222222222222|   121.31222222222222|      29.93554563492064|  85.53083333333336|  69.81983796296296|  69.41876984126982|     121.31222222222222|     121.31222222222222|        29.93554563492064|                0.0|                0.0|                0.0|                   0.0|                   0.0|                     0.0|Commissariat à l'...|               Paris|[{I2738703131, Co...|      0|        0|     0|government|Physics and Astro...|             no_idex| undefined|   public|{\"field\":\"Physics...|           0|      0|       1|      0|Commissariat à l'...|           Paris|[{I2738703131, Co...|      0|        0|     0|government|Physics and Astro...|             no_idex| undefined|   public|{\"field\":\"Physics...|           0|      0|       1|      0|\n",
      "|   I1294671590|     I4210165232|2011|  108|     77|    31|  4.391594474949453|2.7317099150648927| 1.6598845598845597|          16|          54|          38|                  6|                  8|                   56|            14|            32|            31|                    5|                    6|                     39|            2|           22|            7|                   1|                   2|                    17| 0.8341269841269842| 2.1457235621521336| 1.4117439286703353|    0.419047619047619|   0.3521541950113378|     2.2098902288187996| 0.6174603174603175|  1.085640589569161| 1.0286090080354149|    0.36904761904761907|    0.16326530612244897|       1.3317517006802717|0.21666666666666667| 1.0600829725829726|0.38313492063492066|                  0.05|   0.18888888888888888|      0.8781385281385281|Institut de Reche...|      Gif-sur-Yvette|[{I4210113668, Di...|      0|        0|     0|government|Physics and Astro...|             no_idex| undefined|   public|{\"field\":\"Physics...|           0|      0|       1|      0|Centre National d...|           Paris|[{I1294671590, Ce...|      0|        0|     1|government|   Materials Science|             no_idex| undefined|   public|{\"field\":\"Materia...|           0|      0|       1|      0|\n",
      "|   I4210104796|      I100532134|2011|   68|     54|    14| 10.502222222222223| 5.935555555555556|  4.566666666666666|          14|          30|          24|                 17|                 13|                   19|             7|            28|            19|                   12|                    6|                     17|            7|            2|            5|                   5|                   7|                     2| 2.9625000000000004|  4.170277777777779| 3.3694444444444445|   2.7124999999999995|   2.8333333333333335|     2.4983333333333335| 0.6291666666666667| 3.4702777777777785| 1.8361111111111112|     1.2958333333333332|    0.49999999999999994|       1.7983333333333333|  2.333333333333333|                0.7| 1.5333333333333332|    1.4166666666666665|     2.333333333333333|                     0.7|Université Claude...|        Villeurbanne|[{I203339264, Uni...|      0|        1|     0| education|            Medicine|   idex_annulee_lyon|Université|   public|{\"field\":\"Materia...|           1|      0|       1|      0|institut Camille-...|    Villeurbanne|[{I4210104796, in...|      0|        0|     0| education|         Mathematics|             no_idex|     École|    privé|{\"field\":\"Mathema...|           0|      1|       0|      1|\n",
      "|   I4210100151|     I3132279224|2007|   86|     47|    39|  20.28154761904762| 6.034325396825396|  14.24722222222222|          23|          28|          35|                 15|                 20|                   10|             8|            16|            23|                    9|                    7|                      4|           15|           12|           12|                   6|                  13|                     6|  8.791666666666666|  4.779166666666667|  6.710714285714286|    3.913888888888889|   7.5902777777777795|     2.2430555555555554| 1.0555555555555554|  2.101388888888889| 2.8773809523809524|     0.9972222222222222|     0.9652777777777777|       0.4652777777777778|  7.736111111111111| 2.6777777777777776|  3.833333333333333|     2.916666666666667|                 6.625|      1.7777777777777777|Institut Supérieu...|               Lille|[{I3132279224, In...|      0|        0|     0| education|         Engineering|             no_idex|     École|    privé|{\"field\":\"Enginee...|           0|      1|       0|      1|Institut d'Électr...|          Rennes|[{I4210095849, CN...|      0|        1|     1|  facility|         Engineering|             no_idex|Université|   public|{\"field\":\"Enginee...|           1|      0|       1|      0|\n",
      "|        abroad|     I4210144798|2018|   55|     37|    18| 19.662222222222223| 7.328888888888889| 12.333333333333332|          12|          26|          17|                 11|                 24|                   24|             7|            19|            11|                   10|                   14|                     14|            5|            7|            6|                   1|                  10|                    10|  4.805555555555555|  7.856666666666667|                7.0|    3.611111111111111|    9.833333333333332|      9.833333333333332|  1.638888888888889|  3.523333333333333| 2.1666666666666665|      2.611111111111111|     2.8333333333333335|       2.8333333333333335| 3.1666666666666665|  4.333333333333334|  4.833333333333334|                   1.0|                   7.0|                     7.0|Institut Supérieu...|Saint-Ouen-sur-Seine|[{I4210144798, In...|      0|        0|     0|  facility|         Engineering|             no_idex|     École|   public|{\"field\":\"Enginee...|           0|      1|       1|      0|                NULL|            NULL|                NULL|      0|        0|     0|    abroad|                NULL|                NULL|      NULL|     NULL|                NULL|           0|      0|       0|      0|\n",
      "|     I66456633|       I66456633|2020|  105|    105|     0|  50.04662698412697| 50.04662698412697|                0.0|          22|          55|          28|                 30|                 30|                   19|            22|            55|            28|                   30|                   30|                     19|            0|            0|            0|                   0|                   0|                     0| 16.416666666666664| 21.729761904761904| 11.900198412698414|   21.552777777777777|   21.552777777777777|       6.67202380952381| 16.416666666666664| 21.729761904761904| 11.900198412698414|     21.552777777777777|     21.552777777777777|         6.67202380952381|                0.0|                0.0|                0.0|                   0.0|                   0.0|                     0.0| Université de Nîmes|               Nîmes|[{I66456633, Univ...|      0|        1|     0| education|            Medicine|             no_idex|Université|   public|{\"field\":\"Social ...|           1|      0|       1|      0| Université de Nîmes|           Nîmes|[{I66456633, Univ...|      0|        1|     0| education|            Medicine|             no_idex|Université|   public|{\"field\":\"Social ...|           1|      0|       1|      0|\n",
      "|     I96226040|       I96226040|2018|  512|    512|     0| 153.52122218923284|153.52122218923284|                0.0|         105|         268|         139|                220|                220|                   77|           105|           268|           139|                  220|                  220|                     77|            0|            0|            0|                   0|                   0|                     0|  31.88905895691609|  80.81398862914214| 40.818174603174604|    72.61330498866211|    72.61330498866211|     20.423973665223663|  31.88905895691609|  80.81398862914214| 40.818174603174604|      72.61330498866211|      72.61330498866211|       20.423973665223663|                0.0|                0.0|                0.0|                   0.0|                   0.0|                     0.0|Université de Rei...|               Reims|[{I96226040, Univ...|      0|        1|     0| education|            Medicine|             no_idex|Université|   public|{\"field\":\"Medicin...|           1|      0|       1|      0|Université de Rei...|           Reims|[{I96226040, Univ...|      0|        1|     0| education|            Medicine|             no_idex|Université|   public|{\"field\":\"Medicin...|           1|      0|       1|      0|\n",
      "|   I4210134195|     I4210093292|2011|    6|      0|     6| 0.7634920634920636|               0.0| 0.7634920634920636|           1|           3|           2|                  0|                  1|                    1|             0|             0|             0|                    0|                    0|                      0|            1|            3|            2|                   0|                   1|                     1| 0.3333333333333333| 0.2857142857142857|0.14444444444444443|                  0.0|   0.3333333333333333|    0.08333333333333333|                0.0|                0.0|                0.0|                    0.0|                    0.0|                      0.0| 0.3333333333333333| 0.2857142857142857|0.14444444444444443|                   0.0|    0.3333333333333333|     0.08333333333333333|Centre Hospitalie...|         Montpellier|[{I4210093292, Ce...|      0|        0|     0|healthcare|            Medicine|             no_idex| undefined|   public|{\"field\":\"Medicin...|           0|      0|       1|      0|Hôpital Sainte-Ma...|       Marseille|[{I4210087487, As...|      0|        0|     0|healthcare|            Medicine|  idex_aix_marseille| undefined|   public|{\"field\":\"Medicin...|           0|      0|       1|      0|\n",
      "|     I17866349|     I4210130108|2017|    5|      3|     2| 0.6666666666666666|0.5333333333333333|0.13333333333333333|           0|           2|           3|                  1|                  1|                    1|             0|             1|             2|                    1|                    0|                      1|            0|            1|            1|                   0|                   1|                     0|                0.0|0.16666666666666666|                0.5|                 0.25|                 0.05|    0.08333333333333333|                0.0|0.08333333333333333|               0.45|                   0.25|                    0.0|      0.08333333333333333|                0.0|0.08333333333333333|               0.05|                   0.0|                  0.05|                     0.0|Centre d'Étude et...|            Toulouse|[{I4210133643, Dé...|      0|        1|     1|  facility|     Social Sciences|idex_annulee_toul...|Université|   public|{\"field\":\"Social ...|           1|      0|       1|      0|Université de Tou...|        Toulouse|[{I17866349, Univ...|      0|        1|     0| education|         Engineering|idex_annulee_toul...|Université|   public|{\"field\":\"Chemist...|           1|      0|       1|      0|\n",
      "|   I4210162320|     I4210162320|2019|  127|    127|     0|  62.69476190476189| 62.69476190476189|                0.0|          28|          69|          30|                 42|                 42|                   23|            28|            69|            30|                   42|                   42|                     23|            0|            0|            0|                   0|                   0|                     0|  16.09722222222222|   30.6947619047619| 15.902777777777775|    24.90111111111111|    24.90111111111111|       9.29126984126984|  16.09722222222222|   30.6947619047619| 15.902777777777775|      24.90111111111111|      24.90111111111111|         9.29126984126984|                0.0|                0.0|                0.0|                   0.0|                   0.0|                     0.0|             Géoazur|    Sophia Antipolis|[{I4210148025, In...|      1|        1|     1|  facility|Earth and Planeta...|  idex_sorbonne_univ|Université|   public|{\"field\":\"Earth a...|           1|      0|       1|      0|             Géoazur|Sophia Antipolis|[{I4210148025, In...|      1|        1|     1|  facility|Earth and Planeta...|  idex_sorbonne_univ|Université|   public|{\"field\":\"Earth a...|           1|      0|       1|      0|\n",
      "|        abroad|     I4210118410|2007|  163|     20|   143| 145.95555555555558| 4.788888888888889| 141.16666666666669|          35|          81|          47|                  6|                158|                  158|             2|            14|             4|                    2|                   18|                     18|           33|           67|           43|                   4|                 140|                   140| 31.666666666666668|  70.42777777777778| 43.861111111111114|                  4.5|    142.6388888888889|      142.6388888888889|                0.5| 3.4277777777777776| 0.8611111111111112|                    0.5|      4.472222222222222|        4.472222222222222| 31.166666666666668|               67.0|               43.0|                   4.0|    138.16666666666669|      138.16666666666669|Institut thématiq...|               Paris|[{I154526488, Ins...|      0|        0|     0|government|Biochemistry, Gen...|             no_idex| undefined|   public|{\"field\":\"Biochem...|           0|      0|       1|      0|                NULL|            NULL|                NULL|      0|        0|     0|    abroad|                NULL|                NULL|      NULL|     NULL|                NULL|           0|      0|       0|      0|\n",
      "|        abroad|       I70768539|2007|   89|     36|    53| 40.686203703703704| 5.086666666666667|  35.59953703703704|          21|          41|          27|                 14|                 61|                   61|             8|            18|            10|                   11|                   17|                     17|           13|           23|           17|                   3|                  44|                    44|  11.70111111111111| 15.658425925925926| 13.326666666666664|   3.9219444444444442|    35.88388888888888|      35.88388888888888|  1.201111111111111| 2.1422222222222222| 1.7433333333333336|     1.4219444444444447|      2.967222222222222|        2.967222222222222|               10.5| 13.516203703703704| 11.583333333333334|                   2.5|    32.916666666666664|      32.916666666666664|École Nationale S...|               Paris|[{I190752583, Par...|      0|        0|     0| education|         Engineering|            idex_psl|     École|   public|{\"field\":\"Enginee...|           0|      1|       1|      0|                NULL|            NULL|                NULL|      0|        0|     0|    abroad|                NULL|                NULL|      NULL|     NULL|                NULL|           0|      0|       0|      0|\n",
      "|     I19894307|          abroad|2011|  435|    156|   279| 124.04902498205257|15.402425440720897| 108.64659954133171|          90|         232|         113|                239|                 91|                  239|            27|            86|            43|                   93|                   26|                     93|           63|          146|           70|                 146|                  65|                   146| 28.912222222222223| 63.160581619859215|  31.97622113997114|    78.66823646921863|   30.309444444444445|      78.66823646921863| 2.8788888888888886|  7.417762742308197|   5.10577380952381|     10.288354099604101|     3.2650000000000006|       10.288354099604101|  26.03333333333334| 55.742818877551024| 26.870447330447327|     68.37988236961452|    27.044444444444444|       68.37988236961452|                NULL|                NULL|                NULL|      0|        0|     0|    abroad|                NULL|                NULL|      NULL|     NULL|                NULL|           0|      0|       0|      0|Université de Mon...|     Montpellier|[{I19894307, Univ...|      0|        1|     0| education|Earth and Planeta...|             no_idex|Université|   public|{\"field\":\"Environ...|           1|      0|       1|      0|\n",
      "|   I2802436875|     I2802436875|2004|   42|     42|     0| 10.069444444444445|10.069444444444445|                0.0|          13|          17|          12|                 15|                 15|                   11|            13|            17|            12|                   15|                   15|                     11|            0|            0|            0|                   0|                   0|                     0|  3.499999999999999| 3.3861111111111106| 3.1833333333333336|   3.5277777777777772|   3.5277777777777772|     2.4833333333333334|  3.499999999999999| 3.3861111111111106| 3.1833333333333336|     3.5277777777777772|     3.5277777777777772|       2.4833333333333334|                0.0|                0.0|                0.0|                   0.0|                   0.0|                     0.0|Station Biologiqu...|             Roscoff|[{I4210107625, In...|      1|        1|     1|  facility|Environmental Sci...|  idex_sorbonne_univ|Université|   public|{\"field\":\"Earth a...|           1|      0|       1|      0|Station Biologiqu...|         Roscoff|[{I4210107625, In...|      1|        1|     1|  facility|Environmental Sci...|  idex_sorbonne_univ|Université|   public|{\"field\":\"Earth a...|           1|      0|       1|      0|\n",
      "|   I4210091437|     I4210159772|2017|    1|      0|     1|0.07142857142857142|               0.0|0.07142857142857142|           0|           1|           0|                  0|                  0|                    0|             0|             0|             0|                    0|                    0|                      0|            0|            1|            0|                   0|                   0|                     0|                0.0|0.07142857142857142|                0.0|                  0.0|                  0.0|                    0.0|                0.0|                0.0|                0.0|                    0.0|                    0.0|                      0.0|                0.0|0.07142857142857142|                0.0|                   0.0|                   0.0|                     0.0|AMIS - Laboratoir...|            Toulouse|[{I4210107625, In...|      0|        1|     1|  facility|Biochemistry, Gen...|idex_annulee_toul...|Université|   public|{\"field\":\"Arts an...|           1|      0|       1|      0| Sorbonne Paris Cité|           Paris|[{I4210091437, So...|      0|        0|     0|     other|            Medicine|             no_idex| undefined|undefined|{\"field\":\"Medicin...|           0|      0|       0|      0|\n",
      "|     I39804081|     I4210107326|2019|   25|      0|    25|  6.043055555555557|               0.0|  6.043055555555557|           6|          14|           5|                  0|                  7|                   10|             0|             0|             0|                    0|                    0|                      0|            6|           14|            5|                   0|                   7|                    10| 0.9126984126984128|              2.425|  2.705357142857143|                  0.0|   2.1388888888888893|      1.459920634920635|                0.0|                0.0|                0.0|                    0.0|                    0.0|                      0.0| 0.9126984126984128|              2.425|  2.705357142857143|                   0.0|    2.1388888888888893|       1.459920634920635|Institut de Biolo...|               Paris|[{I154526488, Ins...|      1|        1|     1|  facility|Biochemistry, Gen...|  idex_sorbonne_univ|Université|   public|{\"field\":\"Biochem...|           1|      0|       1|      0| Sorbonne Université|           Paris|[{I39804081, Sorb...|      0|        1|     0| education|            Medicine|  idex_sorbonne_univ|Université|   public|{\"field\":\"Medicin...|           1|      0|       1|      0|\n",
      "|   I4210097422|          abroad|2010|   81|     48|    33| 18.027597402597404|4.2248196248196255| 13.802777777777774|          21|          38|          22|                 50|                 18|                   50|            13|            21|            14|                   28|                   13|                     28|            8|           17|            8|                  22|                   5|                    22|  4.891666666666667|  8.759740259740258|  4.376190476190477|   12.558152958152958|    4.319444444444445|     12.558152958152958| 1.3583333333333334| 1.8986291486291487|  0.967857142857143|       2.65537518037518|     1.3194444444444444|         2.65537518037518|  3.533333333333333|  6.861111111111111|  3.408333333333333|     9.902777777777777|    2.9999999999999996|       9.902777777777777|                NULL|                NULL|                NULL|      0|        0|     0|    abroad|                NULL|                NULL|      NULL|     NULL|                NULL|           0|      0|       0|      0|Laboratoire d’Ast...|       Marseille|[{I21491767, Aix-...|      1|        1|     1|  facility|Physics and Astro...|  idex_aix_marseille|Université|   public|{\"field\":\"Physics...|           1|      0|       1|      0|\n",
      "|   I4210123402|     I4210159650|2000|    1|      0|     1|0.08333333333333333|               0.0|0.08333333333333333|           0|           1|           0|                  0|                  0|                    0|             0|             0|             0|                    0|                    0|                      0|            0|            1|            0|                   0|                   0|                     0|                0.0|0.08333333333333333|                0.0|                  0.0|                  0.0|                    0.0|                0.0|                0.0|                0.0|                    0.0|                    0.0|                      0.0|                0.0|0.08333333333333333|                0.0|                   0.0|                   0.0|                     0.0|Laboratoire de Ph...|               Paris|[{I4210159650, La...|      0|        0|     0|  facility|Physics and Astro...|             no_idex| undefined|undefined|{\"field\":\"Physics...|           0|      0|       0|      0|Institut de Physi...|      Strasbourg|[{I4210098836, In...|      1|        1|     1|  facility|   Materials Science|     idex_strasbourg|Université|   public|{\"field\":\"Materia...|           1|      0|       1|      0|\n",
      "|   I4389425387|     I4210121705|2016|   43|     24|    19|  2.829004629629629|0.9423478835978836| 1.8866567460317463|           1|          32|          10|                  5|                  0|                   13|             1|            19|             4|                    5|                    0|                      8|            0|           13|            6|                   0|                   0|                     5|0.08333333333333333| 1.8088657407407407| 0.9368055555555557|  0.28968253968253965|                  0.0|     0.6150462962962964|0.08333333333333333| 0.6944312169312169|0.16458333333333333|    0.28968253968253965|                    0.0|      0.19679232804232805|                0.0|  1.114434523809524| 0.7722222222222221|                   0.0|                   0.0|     0.41825396825396827|Pitié-Salpêtrière...|               Paris|[{I4210097159, As...|      0|        0|     0|healthcare|            Medicine|             no_idex| undefined|   public|{\"field\":\"Medicin...|           0|      0|       1|      0|Centre de Recherc...|           Paris|[{I4389425387, Ce...|      0|        0|     0|  facility|Biochemistry, Gen...|             no_idex| undefined|undefined|{\"field\":\"Medicin...|           0|      0|       0|      0|\n",
      "+--------------+----------------+----+-----+-------+------+-------------------+------------------+-------------------+------------+------------+------------+-------------------+-------------------+---------------------+--------------+--------------+--------------+---------------------+---------------------+-----------------------+-------------+-------------+-------------+--------------------+--------------------+----------------------+-------------------+-------------------+-------------------+---------------------+---------------------+-----------------------+-------------------+-------------------+-------------------+-----------------------+-----------------------+-------------------------+-------------------+-------------------+-------------------+----------------------+----------------------+------------------------+--------------------+--------------------+--------------------+-------+---------+------+----------+--------------------+--------------------+----------+---------+--------------------+------------+-------+--------+-------+--------------------+----------------+--------------------+-------+---------+------+----------+--------------------+--------------------+----------+---------+--------------------+------------+-------+--------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inst_level_flows.cache()\n",
    "inst_level_flows.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c783f731-8af4-43ef-b7e6-7934544cca36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "075ea640-1d78-47e1-a87e-009a44863e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_level_flows.write.mode('overwrite').parquet('file:\\\\' + save_path + 'inst_level_flows.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5a12314-5f67-4035-b0c3-18f66b2587f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_level_flows= spark.read.parquet('file:\\\\' + save_path + 'inst_level_flows.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87e11e99-2b3f-4f55-9567-48e9ae845f10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- inst_id_sender: string (nullable = true)\n",
      " |-- inst_id_receiver: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- total: long (nullable = true)\n",
      " |-- stayers: long (nullable = true)\n",
      " |-- movers: long (nullable = true)\n",
      " |-- total_w: double (nullable = true)\n",
      " |-- stayers_w: double (nullable = true)\n",
      " |-- movers_w: double (nullable = true)\n",
      " |-- total_junior: long (nullable = true)\n",
      " |-- total_senior: long (nullable = true)\n",
      " |-- total_medium: long (nullable = true)\n",
      " |-- total_own_entrant_r: long (nullable = true)\n",
      " |-- total_own_entrant_s: long (nullable = true)\n",
      " |-- total_foreign_entrant: long (nullable = true)\n",
      " |-- stayers_junior: long (nullable = true)\n",
      " |-- stayers_senior: long (nullable = true)\n",
      " |-- stayers_medium: long (nullable = true)\n",
      " |-- stayers_own_entrant_r: long (nullable = true)\n",
      " |-- stayers_own_entrant_s: long (nullable = true)\n",
      " |-- stayers_foreign_entrant: long (nullable = true)\n",
      " |-- movers_junior: long (nullable = true)\n",
      " |-- movers_senior: long (nullable = true)\n",
      " |-- movers_medium: long (nullable = true)\n",
      " |-- movers_own_entrant_r: long (nullable = true)\n",
      " |-- movers_own_entrant_s: long (nullable = true)\n",
      " |-- movers_foreign_entrant: long (nullable = true)\n",
      " |-- total_w_junior: double (nullable = true)\n",
      " |-- total_w_senior: double (nullable = true)\n",
      " |-- total_w_medium: double (nullable = true)\n",
      " |-- total_w_own_entrant_r: double (nullable = true)\n",
      " |-- total_w_own_entrant_s: double (nullable = true)\n",
      " |-- total_w_foreign_entrant: double (nullable = true)\n",
      " |-- stayers_w_junior: double (nullable = true)\n",
      " |-- stayers_w_senior: double (nullable = true)\n",
      " |-- stayers_w_medium: double (nullable = true)\n",
      " |-- stayers_w_own_entrant_r: double (nullable = true)\n",
      " |-- stayers_w_own_entrant_s: double (nullable = true)\n",
      " |-- stayers_w_foreign_entrant: double (nullable = true)\n",
      " |-- movers_w_junior: double (nullable = true)\n",
      " |-- movers_w_senior: double (nullable = true)\n",
      " |-- movers_w_medium: double (nullable = true)\n",
      " |-- movers_w_own_entrant_r: double (nullable = true)\n",
      " |-- movers_w_own_entrant_s: double (nullable = true)\n",
      " |-- movers_w_foreign_entrant: double (nullable = true)\n",
      " |-- name_r: string (nullable = true)\n",
      " |-- city_r: string (nullable = true)\n",
      " |-- parent_r: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- parent_id: string (nullable = true)\n",
      " |    |    |-- parent_name: string (nullable = true)\n",
      " |    |    |-- parent_type: string (nullable = true)\n",
      " |-- fused_r: integer (nullable = true)\n",
      " |-- uni_pub_r: integer (nullable = true)\n",
      " |-- cnrs_r: integer (nullable = true)\n",
      " |-- type_r: string (nullable = true)\n",
      " |-- main_topic_r: string (nullable = true)\n",
      " |-- idex_r: string (nullable = true)\n",
      " |-- type_fr_r: string (nullable = true)\n",
      " |-- secteur_r: string (nullable = true)\n",
      " |-- topic_share_r: string (nullable = true)\n",
      " |-- universite_r: integer (nullable = true)\n",
      " |-- ecole_r: integer (nullable = true)\n",
      " |-- public_r: integer (nullable = true)\n",
      " |-- prive_r: integer (nullable = true)\n",
      " |-- name_s: string (nullable = true)\n",
      " |-- city_s: string (nullable = true)\n",
      " |-- parent_s: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- parent_id: string (nullable = true)\n",
      " |    |    |-- parent_name: string (nullable = true)\n",
      " |    |    |-- parent_type: string (nullable = true)\n",
      " |-- fused_s: integer (nullable = true)\n",
      " |-- uni_pub_s: integer (nullable = true)\n",
      " |-- cnrs_s: integer (nullable = true)\n",
      " |-- type_s: string (nullable = true)\n",
      " |-- main_topic_s: string (nullable = true)\n",
      " |-- idex_s: string (nullable = true)\n",
      " |-- type_fr_s: string (nullable = true)\n",
      " |-- secteur_s: string (nullable = true)\n",
      " |-- topic_share_s: string (nullable = true)\n",
      " |-- universite_s: integer (nullable = true)\n",
      " |-- ecole_s: integer (nullable = true)\n",
      " |-- public_s: integer (nullable = true)\n",
      " |-- prive_s: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inst_level_flows.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20103ec-7c4b-4782-8bbe-7f13746d6b31",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Institution level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd467a1f-74f3-4a25-83af-604db13905fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_level_flows = (inst_level_flows\n",
    "                    .groupBy(func.col('inst_id_receiver').alias('inst_id'), 'year')\n",
    "                    .agg(*[func.first(col + '_r').alias(col)\n",
    "                           for col in ['name','city','parent','fused','uni_pub','cnrs','type','main_topic','idex','type_fr','secteur','prive','ecole','universite','public']],\n",
    "                         *[func.sum(col).alias(col) for col in inst_level_flows.columns if \"stayer\" in col or \"mover\" in col or \"total\" in col]\n",
    "                        )\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79934c1d-db45-45f4-9ea1-80df5ad83826",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+--------------------+--------------------+--------------------+-----+-------+----+----------+--------------------+--------------------+----------+---------+-----+-----+----------+------+-----+-------+------+------------------+------------------+------------------+------------+------------+------------+-------------------+-------------------+---------------------+--------------+--------------+--------------+---------------------+---------------------+-----------------------+-------------+-------------+-------------+--------------------+--------------------+----------------------+------------------+------------------+------------------+---------------------+---------------------+-----------------------+------------------+-------------------+------------------+-----------------------+-----------------------+-------------------------+------------------+------------------+------------------+----------------------+----------------------+------------------------+\n",
      "|   inst_id|year|                name|                city|              parent|fused|uni_pub|cnrs|      type|          main_topic|                idex|   type_fr|  secteur|prive|ecole|universite|public|total|stayers|movers|           total_w|         stayers_w|          movers_w|total_junior|total_senior|total_medium|total_own_entrant_r|total_own_entrant_s|total_foreign_entrant|stayers_junior|stayers_senior|stayers_medium|stayers_own_entrant_r|stayers_own_entrant_s|stayers_foreign_entrant|movers_junior|movers_senior|movers_medium|movers_own_entrant_r|movers_own_entrant_s|movers_foreign_entrant|    total_w_junior|    total_w_senior|    total_w_medium|total_w_own_entrant_r|total_w_own_entrant_s|total_w_foreign_entrant|  stayers_w_junior|   stayers_w_senior|  stayers_w_medium|stayers_w_own_entrant_r|stayers_w_own_entrant_s|stayers_w_foreign_entrant|   movers_w_junior|   movers_w_senior|   movers_w_medium|movers_w_own_entrant_r|movers_w_own_entrant_s|movers_w_foreign_entrant|\n",
      "+----------+----+--------------------+--------------------+--------------------+-----+-------+----+----------+--------------------+--------------------+----------+---------+-----+-----+----------+------+-----+-------+------+------------------+------------------+------------------+------------+------------+------------+-------------------+-------------------+---------------------+--------------+--------------+--------------+---------------------+---------------------+-----------------------+-------------+-------------+-------------+--------------------+--------------------+----------------------+------------------+------------------+------------------+---------------------+---------------------+-----------------------+------------------+-------------------+------------------+-----------------------+-----------------------+-------------------------+------------------+------------------+------------------+----------------------+----------------------+------------------------+\n",
      "|I100532134|2016|Université Claude...|        Villeurbanne|[{I203339264, Uni...|    0|      1|   0| education|            Medicine|   idex_annulee_lyon|Université|   public|    0|    0|         1|     1| 7380|   4556|  2824|1451.7642288267284|  614.412955100455| 837.3512737262736|        1702|        3852|        1826|               1649|               2016|                 1952|           729|          2686|          1141|                 1035|                 1118|                   1081|          973|         1166|          685|                 614|                 898|                   871| 580.4301587301588| 522.7808233433234| 348.5532467532467|    528.5874999999999|    547.1985578825385|      399.7229908979907|153.80476190476196| 289.05653374403363| 171.5516594516594|     214.81964285714287|      217.2205875614134|       124.51071428571434|426.62539682539676|233.72428959928965|177.00158730158728|     313.7678571428571|    329.97797032112516|      275.21227661227664|\n",
      "|I102190016|2020|University of New...|              Noumea|[{I102190016, Uni...|    0|      1|   0| education|     Social Sciences|             no_idex|Université|   public|    0|    0|         1|     1|  281|    142|   139|125.92301587301588| 52.57619047619047| 73.34682539682542|          87|         138|          56|                 92|                 76|                   68|            27|            89|            26|                   42|                   42|                     38|           60|           49|           30|                  50|                  34|                    30| 52.34444444444445| 44.16190476190477|29.416666666666664|   62.949999999999996|   42.547222222222224|      31.51666666666667| 9.533333333333335| 26.376190476190487|16.666666666666668|                   23.2|     22.097619047619045|       13.900000000000004| 42.81111111111112| 17.78571428571428|             12.75|                 39.75|    20.449603174603173|      17.616666666666667|\n",
      "|I102272798|1982|              INSEAD|       Fontainebleau|[{I102272798, INS...|    0|      0|   0| education|Business, Managem...|  idex_sorbonne_univ|     École|    privé|    1|    1|         0|     0|   34|     11|    23|             27.25|               7.0|             20.25|          16|          11|           7|                 14|                 19|                   21|             6|             3|             2|                    5|                    7|                      5|           10|            8|            5|                   9|                  12|                    16|              14.0| 6.749999999999999|               6.5|                 13.5|   16.083333333333336|                   17.5|               4.0|                1.5|               1.5|                    4.5|                    5.0|                      1.5|              10.0| 5.249999999999999|               5.0|                   9.0|    11.083333333333334|                    16.0|\n",
      "|I102272798|1998|              INSEAD|       Fontainebleau|[{I102272798, INS...|    0|      0|   0| education|Business, Managem...|  idex_sorbonne_univ|     École|    privé|    1|    1|         0|     0|   58|     33|    25|47.583333333333336|22.583333333333332|              25.0|          24|          14|          20|                 23|                 21|                   32|             6|            13|            14|                    8|                   12|                     23|           18|            1|            6|                  15|                   9|                     9|22.333333333333336|              11.5|             13.75|                 23.0|                 18.0|     22.583333333333336| 4.333333333333333|               10.5| 7.750000000000001|                    8.0|                    9.0|       13.583333333333334|              18.0|               1.0|               6.0|                  15.0|                   9.0|                     9.0|\n",
      "|I102516824|2019|Université de Tec...|           Compiègne|[{I102516824, Uni...|    0|      1|   0| education|         Engineering|  idex_sorbonne_univ|     École|   public|    0|    1|         0|     1|  437|    260|   177|155.49999999999997| 60.43333333333335| 95.06666666666665|         142|         197|          98|                160|                139|                  154|            44|           144|            72|                   86|                   78|                     85|           98|           53|           26|                  74|                  61|                    69| 72.36666666666667| 51.93333333333333|31.199999999999996|    82.33333333333333|    55.40019841269842|      46.56666666666667|12.616666666666667| 31.066666666666663|             16.75|     28.999999999999996|     24.901388888888885|       12.033333333333331|59.750000000000014| 20.86666666666667|14.450000000000001|    53.333333333333336|    30.498809523809516|       34.53333333333333|\n",
      "|I103084370|2011|      Total (France)|               Paris|[{I103084370, Tot...|    0|      0|   0|   company|         Engineering|             no_idex|     Firme|    privé|    1|    0|         0|     0|  584|    192|   392| 372.2071428571429|135.70000000000005|236.50714285714284|         267|         172|         145|                234|                212|                  217|            65|            59|            68|                   81|                   95|                     54|          202|          113|           77|                 153|                 117|                   163| 211.5595238095238| 73.03928571428571|  87.6083333333333|   205.83333333333334|     151.084268707483|     112.47142857142858|48.833333333333336|  40.78333333333334|46.083333333333336|      69.83333333333334|      74.41249999999998|       31.866666666666667|162.72619047619045| 32.25595238095238|41.525000000000006|                 136.0|       76.671768707483|        80.6047619047619|\n",
      "| I10342815|1996|International Spa...|Illkirch-Graffens...|[{I10342815, Inte...|    0|      0|   0| education|         Engineering|             no_idex|     École|   public|    0|    1|         0|     1|    8|      2|     6|               4.5|               1.0|               3.5|           2|           3|           3|                  2|                  2|                    4|             0|             2|             0|                    0|                    1|                      2|            2|            1|            3|                   2|                   1|                     2|               2.0|               2.0|               0.5|                  2.0|                  1.5|                    3.0|               0.0|                1.0|               0.0|                    0.0|                    0.5|                      1.0|               2.0|               1.0|               0.5|                   2.0|                   1.0|                     2.0|\n",
      "|I103562704|2000|  ESI Group (France)|               Paris|[{I103562704, ESI...|    0|      0|   0|   company|         Engineering|             no_idex|     Firme|    privé|    1|    0|         0|     0|   11|      3|     8|               7.0|               3.0|               4.0|           5|           1|           5|                  6|                  3|                    1|             0|             1|             2|                    1|                    1|                      1|            5|            0|            3|                   5|                   2|                     0| 3.666666666666667|               1.0|2.3333333333333335|    4.666666666666667|   1.2222222222222223|                    1.0|               0.0|                1.0|               2.0|                    1.0|                    1.0|                      1.0| 3.666666666666667|               0.0|0.3333333333333333|     3.666666666666667|    0.2222222222222222|                     0.0|\n",
      "|I103562704|2004|  ESI Group (France)|               Paris|[{I103562704, ESI...|    0|      0|   0|   company|         Engineering|             no_idex|     Firme|    privé|    1|    0|         0|     0|   34|     12|    22|15.816666666666666| 5.199999999999999|10.616666666666667|          11|          15|           8|                  7|                  9|                   13|             1|            10|             1|                    1|                    2|                      9|           10|            5|            7|                   6|                   7|                     4| 6.116666666666667| 5.533333333333333| 4.166666666666666|    5.666666666666667|    5.478571428571429|     3.5333333333333328|               1.0| 3.1999999999999993|               1.0|                    1.0|     1.0285714285714285|       2.1999999999999993| 5.116666666666667| 2.333333333333333|3.1666666666666665|     4.666666666666667|                  4.45|      1.3333333333333333|\n",
      "|I106530797|1996|                ITER|    Vinon-sur-Verdon|[{I106530797, ITE...|    0|      0|   0|     other|         Engineering|             no_idex| undefined|undefined|    0|    0|         0|     0|    3|      0|     3|               2.0|               0.0|               2.0|           1|           1|           1|                  1|                  0|                    1|             0|             0|             0|                    0|                    0|                      0|            1|            1|            1|                   1|                   0|                     1|               1.0|               0.5|               0.5|                  1.0|                  0.0|                    0.5|               0.0|                0.0|               0.0|                    0.0|                    0.0|                      0.0|               1.0|               0.5|               0.5|                   1.0|                   0.0|                     0.5|\n",
      "|I106530797|2010|                ITER|    Vinon-sur-Verdon|[{I106530797, ITE...|    0|      0|   0|     other|         Engineering|             no_idex| undefined|undefined|    0|    0|         0|     0|  313|    184|   129|            197.75| 93.99999999999999|            103.75|          64|         195|          54|                 48|                120|                  216|            20|           137|            27|                   14|                   57|                    144|           44|           58|           27|                  34|                  63|                    72|              59.0| 99.41666666666667|39.333333333333336|                 44.5|    80.94444444444444|     127.41666666666666|              15.5|  60.16666666666667|18.333333333333332|                   11.0|     25.569444444444443|        72.16666666666666|              43.5| 39.25000000000001|              21.0|                  33.5|                55.375|       55.25000000000001|\n",
      "|I108523894|2011|     Soitec (France)|              Bernin|[{I108523894, Soi...|    0|      0|   0|   company|         Engineering|             no_idex|     Firme|    privé|    1|    0|         0|     0|   77|     60|    17| 43.16666666666667| 33.75000000000001| 9.416666666666666|          17|          36|          24|                 22|                 18|                   30|            13|            27|            20|                   18|                   14|                     28|            4|            9|            4|                   4|                   4|                     2|              12.5|13.916666666666664|             16.75|                 15.0|                11.15|     13.499999999999998|               8.5| 10.499999999999998|             14.75|                   11.0|                   9.75|       11.499999999999998|               4.0| 3.416666666666667|1.9999999999999998|                   4.0|    1.4000000000000001|                     2.0|\n",
      "|I110736937|1983|  Délégation Paris 5|               Paris|[{I154526488, Ins...|    0|      0|   0|government|            Medicine|             no_idex| undefined|   public|    0|    0|         0|     1|   12|      2|    10|3.8333333333333335|               1.0| 2.833333333333333|           2|           7|           3|                  2|                  2|                    1|             0|             0|             2|                    0|                    0|                      0|            2|            7|            1|                   2|                   2|                     1|               1.0|               1.5|1.3333333333333333|                  1.0|   0.2222222222222222|                    0.5|               0.0|                0.0|               1.0|                    0.0|                    0.0|                      0.0|               1.0|               1.5|0.3333333333333333|                   1.0|    0.2222222222222222|                     0.5|\n",
      "|I110736937|1984|  Délégation Paris 5|               Paris|[{I154526488, Ins...|    0|      0|   0|government|            Medicine|             no_idex| undefined|   public|    0|    0|         0|     1|   38|      0|    38| 9.866666666666665|               0.0| 9.866666666666665|          10|          14|          14|                  2|                  9|                    2|             0|             0|             0|                    0|                    0|                      0|           10|           14|           14|                   2|                   9|                     2| 4.166666666666667|1.3666666666666665| 4.333333333333333|                  1.5|   3.2500000000000004|     0.8333333333333333|               0.0|                0.0|               0.0|                    0.0|                    0.0|                      0.0| 4.166666666666667|1.3666666666666665| 4.333333333333333|                   1.5|    3.2500000000000004|      0.8333333333333333|\n",
      "|I112936343|2006|École Centrale de...|              Écully|[{I203339264, Uni...|    0|      1|   0| education|         Engineering|   idex_annulee_lyon|     École|   public|    0|    1|         0|     1|  312|    164|   148| 99.44999999999997|38.516666666666666| 60.93333333333334|         129|         114|          69|                126|                119|                   72|            60|            67|            37|                   78|                   66|                     43|           69|           47|           32|                  48|                  53|                    29|             60.65|21.583333333333332|17.216666666666665|   52.349999999999994|              39.9775|     19.683333333333334|17.166666666666668| 14.116666666666665| 7.233333333333333|     21.283333333333335|     19.091388888888886|        6.733333333333334|43.483333333333334| 7.466666666666666| 9.983333333333334|     31.06666666666666|    20.886111111111113|                   12.95|\n",
      "| I11559806|1990|École Normale Sup...|      Gif-sur-Yvette|[{I277688954, Uni...|    1|      1|   0| education|    Computer Science|   idex_paris_saclay|Université|   public|    0|    0|         1|     1|   57|     24|    33|             21.25| 6.250000000000001|14.999999999999998|          24|          12|          21|                 32|                 21|                    4|             6|             5|            13|                   19|                   11|                      2|           18|            7|            8|                  13|                  10|                     2|13.333333333333334|              3.25| 4.666666666666665|   13.666666666666666|    7.847222222222221|      2.333333333333333|               3.0|               0.75|2.4999999999999996|                    5.0|     3.7916666666666665|                      1.0|10.333333333333332|               2.5|2.1666666666666665|     8.666666666666666|     4.055555555555555|      1.3333333333333333|\n",
      "| I11559806|2006|École Normale Sup...|      Gif-sur-Yvette|[{I277688954, Uni...|    1|      1|   0| education|    Computer Science|   idex_paris_saclay|Université|   public|    0|    0|         1|     1|  469|    231|   238| 149.7119047619048|55.226190476190496|  94.4857142857143|         188|         148|         133|                169|                159|                   88|            73|            89|            69|                   89|                   94|                     39|          115|           59|           64|                  80|                  65|                    49|             88.15|31.076190476190476|30.485714285714284|    75.88333333333334|    59.88769841269841|                   29.2|22.866666666666667|  16.04285714285714|16.316666666666666|      28.73333333333333|      30.11944444444444|        8.750000000000002| 65.28333333333335|15.033333333333335|14.169047619047618|     47.15000000000001|     29.76825396825397|                   20.45|\n",
      "|I117345614|1995|Institut Français...|               Paris|[{I117345614, Ins...|    0|      0|   0| nonprofit|     Social Sciences|             no_idex| undefined|    privé|    1|    0|         0|     0|    3|      0|     3|               2.5|               0.0|               2.5|           2|           1|           0|                  2|                  0|                    2|             0|             0|             0|                    0|                    0|                      0|            2|            1|            0|                   2|                   0|                     2|               2.0|               0.5|               0.0|                  2.0|                  0.0|                    2.0|               0.0|                0.0|               0.0|                    0.0|                    0.0|                      0.0|               2.0|               0.5|               0.0|                   2.0|                   0.0|                     2.0|\n",
      "| I11935315|2020|École Nationale S...|         Montpellier|[{I11935315, Écol...|    0|      0|   0| education|           Chemistry|             no_idex|     École|   public|    0|    1|         0|     1|   76|     11|    65| 25.13333333333334|0.8666666666666667| 24.26666666666667|          31|          36|           9|                 23|                 18|                   29|             2|             6|             3|                    2|                    4|                      3|           29|           30|            6|                  21|                  14|                    26|              17.0| 5.883333333333334|              2.25|                 14.5|    5.311111111111111|      9.983333333333329|0.3333333333333333|0.19999999999999998|0.3333333333333333|     0.3333333333333333|    0.47777777777777775|       0.3333333333333333|16.666666666666668|5.6833333333333345|1.9166666666666665|    14.166666666666668|     4.833333333333333|       9.649999999999997|\n",
      "|I119865316|2002|École Nationale d...|              Tarbes|[{I119865316, Éco...|    0|      0|   0| education|         Engineering|idex_annulee_toul...|     École|   public|    0|    1|         0|     1|   30|      8|    22|14.583333333333334|               3.0|11.583333333333332|          12|           7|          11|                 15|                 12|                    4|             2|             2|             4|                    6|                    6|                      4|           10|            5|            7|                   9|                   6|                     0|              10.0|0.7500000000000001|3.8333333333333335|                 11.0|   4.7861111111111105|                    1.5|               0.5|                0.5|               2.0|                    2.5|                   2.25|                      1.5|               9.5|              0.25|1.8333333333333335|                   8.5|     2.536111111111111|                     0.0|\n",
      "+----------+----+--------------------+--------------------+--------------------+-----+-------+----+----------+--------------------+--------------------+----------+---------+-----+-----+----------+------+-----+-------+------+------------------+------------------+------------------+------------+------------+------------+-------------------+-------------------+---------------------+--------------+--------------+--------------+---------------------+---------------------+-----------------------+-------------+-------------+-------------+--------------------+--------------------+----------------------+------------------+------------------+------------------+---------------------+---------------------+-----------------------+------------------+-------------------+------------------+-----------------------+-----------------------+-------------------------+------------------+------------------+------------------+----------------------+----------------------+------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inst_level_flows.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1045a3da-6fdf-4572-9932-d0e8806e33b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_level_flows.write.mode('overwrite').parquet('file:\\\\' + save_path + 'unilateral_inst_level_flows.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59287afa-b146-435a-9ded-546c60ada9dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "595fdca6-eee7-449e-a1b3-479c4e092a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.clearCache()\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67cdac8-2ec4-4992-9007-28175185c47e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eedac0-3fc9-433b-90fe-d4326cb0f01b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inst_level_flows_moves = (inst_level_flows\n",
    "\n",
    "                          .drop('stayers')\n",
    "                         )\n",
    "inst_level_flows_moves.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ebed0af9-dae4-4918-a19d-c3fbd43f09c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "au_inst_level_flow.filter( (func.col('inst_id_receiver')==\"I57995698\")  & (func.col('inst_id_sender').isin([\"I187986737\"]))\n",
    "                          & (func.col('year')==2020)).select('author_id','inst_id_sender','inst_id_receiver').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b672ac1e-0e7d-417b-93a5-1e834025371f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "au_inst_level_flow.filter( (func.col('inst_id_receiver')==\"I57995698\")  & (func.col('inst_id_sender')==\"I187986737\")\n",
    "                          & (func.col('year')==2020)).select('author_id').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d44e1083-1134-4da8-8758-d4f87ab845f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+----------------+-------+------+--------+\n",
      "|year|inst_id_sender|inst_id_receiver|stayers|movers|movers_w|\n",
      "+----+--------------+----------------+-------+------+--------+\n",
      "|2015|    I187986737|       I57995698|      1|     0|     0.0|\n",
      "|2018|    I187986737|       I57995698|      3|     0|     0.0|\n",
      "|2006|    I187986737|       I57995698|      1|     0|     0.0|\n",
      "|2001|    I187986737|       I57995698|      1|     0|     0.0|\n",
      "|2005|    I187986737|       I57995698|      1|     0|     0.0|\n",
      "|2010|    I187986737|       I57995698|      2|     0|     0.0|\n",
      "|2017|    I187986737|       I57995698|      2|     0|     0.0|\n",
      "|2016|    I187986737|       I57995698|      2|     1|     0.5|\n",
      "|2011|    I187986737|       I57995698|      2|     1|    0.25|\n",
      "|2008|    I187986737|       I57995698|      2|     0|     0.0|\n",
      "|1994|    I187986737|       I57995698|      1|     0|     0.0|\n",
      "|2012|    I187986737|       I57995698|      2|     0|     0.0|\n",
      "|2002|    I187986737|       I57995698|      1|     0|     0.0|\n",
      "|2013|    I187986737|       I57995698|      2|     0|     0.0|\n",
      "|2003|    I187986737|       I57995698|      1|     0|     0.0|\n",
      "|2019|    I187986737|       I57995698|      1|     0|     0.0|\n",
      "|1993|    I187986737|       I57995698|      1|     0|     0.0|\n",
      "|2014|    I187986737|       I57995698|      1|     0|     0.0|\n",
      "|2000|    I187986737|       I57995698|      1|     0|     0.0|\n",
      "|2007|    I187986737|       I57995698|      1|     1|     0.5|\n",
      "+----+--------------+----------------+-------+------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inst_level_flows.filter( (func.col('inst_id_receiver')==\"I57995698\")  & (func.col('inst_id_sender')==\"I187986737\")\n",
    "                        ).select('year','inst_id_sender','inst_id_receiver','stayers','movers','movers_w').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5bb7e234-7daf-41b9-9718-600527da5496",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(year=1980, movers=1, stayers=0, movers_w=1.0, stayers_w=0.0),\n",
       " Row(year=1982, movers=3, stayers=0, movers_w=1.5, stayers_w=0.0),\n",
       " Row(year=1984, movers=2, stayers=0, movers_w=0.3333333333333333, stayers_w=0.0),\n",
       " Row(year=1985, movers=1, stayers=0, movers_w=1.0, stayers_w=0.0),\n",
       " Row(year=1988, movers=5, stayers=2, movers_w=1.5833333333333333, stayers_w=0.5),\n",
       " Row(year=1989, movers=1, stayers=0, movers_w=0.3333333333333333, stayers_w=0.0),\n",
       " Row(year=1990, movers=1, stayers=0, movers_w=0.5, stayers_w=0.0),\n",
       " Row(year=1991, movers=1, stayers=0, movers_w=0.3333333333333333, stayers_w=0.0),\n",
       " Row(year=1992, movers=3, stayers=0, movers_w=1.0, stayers_w=0.0),\n",
       " Row(year=1993, movers=0, stayers=5, movers_w=0.0, stayers_w=0.8333333333333333),\n",
       " Row(year=1994, movers=1, stayers=3, movers_w=0.25, stayers_w=0.3333333333333333),\n",
       " Row(year=1995, movers=1, stayers=0, movers_w=1.0, stayers_w=0.0),\n",
       " Row(year=1996, movers=11, stayers=0, movers_w=5.083333333333333, stayers_w=0.0),\n",
       " Row(year=1997, movers=7, stayers=2, movers_w=3.333333333333333, stayers_w=0.25),\n",
       " Row(year=1998, movers=6, stayers=1, movers_w=3.083333333333333, stayers_w=1.0),\n",
       " Row(year=1999, movers=10, stayers=12, movers_w=3.416666666666667, stayers_w=2.283333333333333),\n",
       " Row(year=2000, movers=9, stayers=16, movers_w=2.6166666666666667, stayers_w=2.033333333333333),\n",
       " Row(year=2001, movers=16, stayers=23, movers_w=5.4833333333333325, stayers_w=3.5666666666666678),\n",
       " Row(year=2002, movers=12, stayers=30, movers_w=2.983333333333334, stayers_w=3.9916666666666663),\n",
       " Row(year=2003, movers=53, stayers=30, movers_w=5.78703703703704, stayers_w=3.7833333333333328),\n",
       " Row(year=2004, movers=23, stayers=45, movers_w=5.126190476190475, stayers_w=5.683333333333333),\n",
       " Row(year=2005, movers=42, stayers=45, movers_w=9.185714285714285, stayers_w=4.3166666666666655),\n",
       " Row(year=2006, movers=40, stayers=88, movers_w=9.716666666666669, stayers_w=8.566666666666668),\n",
       " Row(year=2007, movers=156, stayers=119, movers_w=44.34285714285715, stayers_w=13.087301587301583),\n",
       " Row(year=2008, movers=189, stayers=203, movers_w=59.80515873015873, stayers_w=30.750000000000007),\n",
       " Row(year=2009, movers=122, stayers=267, movers_w=46.53253968253967, stayers_w=40.244444444444454),\n",
       " Row(year=2010, movers=158, stayers=348, movers_w=66.48333333333333, stayers_w=57.102380952380955),\n",
       " Row(year=2011, movers=99, stayers=383, movers_w=50.85, stayers_w=64.15357142857144),\n",
       " Row(year=2012, movers=140, stayers=366, movers_w=51.03452380952381, stayers_w=72.12301587301589),\n",
       " Row(year=2013, movers=112, stayers=369, movers_w=49.60000000000001, stayers_w=69.36666666666665),\n",
       " Row(year=2014, movers=130, stayers=347, movers_w=69.26666666666667, stayers_w=63.09285714285714),\n",
       " Row(year=2015, movers=154, stayers=341, movers_w=64.47692307692309, stayers_w=72.54682539682543),\n",
       " Row(year=2016, movers=125, stayers=370, movers_w=60.40952380952381, stayers_w=78.66904761904765),\n",
       " Row(year=2017, movers=156, stayers=390, movers_w=67.04285714285713, stayers_w=78.50833333333333),\n",
       " Row(year=2018, movers=143, stayers=351, movers_w=76.84444444444443, stayers_w=77.27619047619046),\n",
       " Row(year=2019, movers=128, stayers=327, movers_w=64.8547619047619, stayers_w=75.79166666666667),\n",
       " Row(year=2020, movers=153, stayers=326, movers_w=69.11944444444445, stayers_w=84.4857142857143)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inst_level_flows.filter(func.col('inst_id_receiver')==\"I57995698\").groupBy('year').agg(func.sum('movers').alias('movers'), func.sum('stayers').alias('stayers'),\n",
    "                                                                                             func.sum('movers_w').alias('movers_w'),\n",
    "                                                                                      func.sum('stayers_w').alias('stayers_w')).sort('year').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7242b7c9-7486-4d62-a615-e015f5437524",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------+----+-----+-------+------+--------------------+--------------------+--------------------+------------+------------+------------+-------------------+-------------------+---------------------+--------------+--------------+--------------+---------------------+---------------------+-----------------------+-------------+-------------+-------------+--------------------+--------------------+----------------------+--------------+--------------------+-------------------+---------------------+---------------------+-----------------------+----------------+--------------------+-------------------+-----------------------+-----------------------+-------------------------+---------------+--------------------+-------------------+----------------------+----------------------+------------------------+--------------------+------+--------------------+-------+---------+------+---------+--------------------+--------------------+-------+---------+---------+--------------------+-----------------+--------------------+-------+---------+------+----------+--------------------+--------------------+-----------------+----------+---------+------------+-------+------------+-------+--------+-------+--------+-------+\n",
      "|inst_id_receiver|inst_id_sender|year|total|stayers|movers|             total_w|           stayers_w|            movers_w|total_junior|total_senior|total_medium|total_own_entrant_r|total_own_entrant_s|total_foreign_entrant|stayers_junior|stayers_senior|stayers_medium|stayers_own_entrant_r|stayers_own_entrant_s|stayers_foreign_entrant|movers_junior|movers_senior|movers_medium|movers_own_entrant_r|movers_own_entrant_s|movers_foreign_entrant|total_w_junior|      total_w_senior|     total_w_medium|total_w_own_entrant_r|total_w_own_entrant_s|total_w_foreign_entrant|stayers_w_junior|    stayers_w_senior|   stayers_w_medium|stayers_w_own_entrant_r|stayers_w_own_entrant_s|stayers_w_foreign_entrant|movers_w_junior|     movers_w_senior|    movers_w_medium|movers_w_own_entrant_r|movers_w_own_entrant_s|movers_w_foreign_entrant|              name_r|city_r|            parent_r|fused_r|uni_pub_r|cnrs_r|   type_r|        main_topic_r|       topic_share_r| idex_r|type_fr_r|secteur_r|              name_s|           city_s|            parent_s|fused_s|uni_pub_s|cnrs_s|    type_s|        main_topic_s|       topic_share_s|           idex_s| type_fr_s|secteur_s|universite_r|ecole_r|universite_s|ecole_s|public_r|prive_r|public_s|prive_s|\n",
      "+----------------+--------------+----+-----+-------+------+--------------------+--------------------+--------------------+------------+------------+------------+-------------------+-------------------+---------------------+--------------+--------------+--------------+---------------------+---------------------+-----------------------+-------------+-------------+-------------+--------------------+--------------------+----------------------+--------------+--------------------+-------------------+---------------------+---------------------+-----------------------+----------------+--------------------+-------------------+-----------------------+-----------------------+-------------------------+---------------+--------------------+-------------------+----------------------+----------------------+------------------------+--------------------+------+--------------------+-------+---------+------+---------+--------------------+--------------------+-------+---------+---------+--------------------+-----------------+--------------------+-------+---------+------+----------+--------------------+--------------------+-----------------+----------+---------+------------+-------+------------+-------+--------+-------+--------+-------+\n",
      "|       I57995698|   I1339876250|2020|    2|      1|     1| 0.41666666666666663| 0.16666666666666666|                0.25|           0|           2|           0|                  0|                  1|                    1|             0|             1|             0|                    0|                    1|                      1|            0|            1|            0|                   0|                   0|                     0|           0.0| 0.41666666666666663|                0.0|                  0.0|  0.16666666666666666|    0.16666666666666666|             0.0| 0.16666666666666666|                0.0|                    0.0|    0.16666666666666666|      0.16666666666666666|            0.0|                0.25|                0.0|                   0.0|                   0.0|                     0.0|Paris School of E...| Paris|[{I57995698, Pari...|      0|        0|     1|education|Economics, Econom...|{\"field\":\"Social ...|no_idex|    École|   public|Institut National...|            Paris|[{I1339876250, In...|      0|        0|     0|  facility|Economics, Econom...|{\"field\":\"Economi...|          no_idex| undefined|   public|           0|      1|           0|      0|       1|      0|       1|      0|\n",
      "|       I57995698|    I171048554|2020|    1|      0|     1|  0.3333333333333333|                 0.0|  0.3333333333333333|           0|           1|           0|                  0|                  0|                    0|             0|             0|             0|                    0|                    0|                      0|            0|            1|            0|                   0|                   0|                     0|           0.0|  0.3333333333333333|                0.0|                  0.0|                  0.0|                    0.0|             0.0|                 0.0|                0.0|                    0.0|                    0.0|                      0.0|            0.0|  0.3333333333333333|                0.0|                   0.0|                   0.0|                     0.0|Paris School of E...| Paris|[{I57995698, Pari...|      0|        0|     1|education|Economics, Econom...|{\"field\":\"Social ...|no_idex|    École|   public|Centre de Recherc...|            Paris|[{I4210141950, In...|      0|        1|     1|  facility|         Mathematics|{\"field\":\"Mathema...|         idex_psl|Université|   public|           0|      1|           1|      0|       1|      0|       1|      0|\n",
      "|       I57995698|    I185839726|2020|    1|      4|     0| 0.11428571428571428| 0.11428571428571428|                 0.0|           0|           0|           4|                  0|                  0|                    4|             0|             0|             4|                    0|                    0|                      4|            0|            0|            0|                   0|                   0|                     0|           0.0|                 0.0|0.11428571428571428|                  0.0|                  0.0|    0.11428571428571428|             0.0|                 0.0|0.11428571428571428|                    0.0|                    0.0|      0.11428571428571428|            0.0|                 0.0|                0.0|                   0.0|                   0.0|                     0.0|Paris School of E...| Paris|[{I57995698, Pari...|      0|        0|     1|education|Economics, Econom...|{\"field\":\"Social ...|no_idex|    École|   public|Institut Universi...|            Paris|[{I185839726, Ins...|      0|        0|     0| education|          Psychology|{\"field\":\"Neurosc...|          no_idex|     École|   public|           0|      1|           0|      1|       1|      0|       1|      0|\n",
      "|       I57995698|    I201298700|2020|    7|     23|     0|  1.8523809523809522|  1.8523809523809522|                 0.0|           0|          19|           4|                  7|                  4|                    2|             0|            19|             4|                    7|                    4|                      2|            0|            0|            0|                   0|                   0|                     0|           0.0|  1.1857142857142857| 0.6666666666666666|   0.6261904761904761|   0.5833333333333333|     0.3333333333333333|             0.0|  1.1857142857142857| 0.6666666666666666|     0.6261904761904761|     0.5833333333333333|       0.3333333333333333|            0.0|                 0.0|                0.0|                   0.0|                   0.0|                     0.0|Paris School of E...| Paris|[{I57995698, Pari...|      0|        0|     1|education|Economics, Econom...|{\"field\":\"Social ...|no_idex|    École|   public|    Banque de France|            Paris|[{I201298700, Ban...|      0|        0|     0|     other|Economics, Econom...|{\"field\":\"Economi...|          no_idex| undefined|   public|           0|      1|           0|      0|       1|      0|       1|      0|\n",
      "|       I57995698|   I2799502834|2020|    1|      0|     1| 0.03571428571428571|                 0.0| 0.03571428571428571|           0|           0|           1|                  0|                  0|                    0|             0|             0|             0|                    0|                    0|                      0|            0|            0|            1|                   0|                   0|                     0|           0.0|                 0.0|0.03571428571428571|                  0.0|                  0.0|                    0.0|             0.0|                 0.0|                0.0|                    0.0|                    0.0|                      0.0|            0.0|                 0.0|0.03571428571428571|                   0.0|                   0.0|                     0.0|Paris School of E...| Paris|[{I57995698, Pari...|      0|        0|     1|education|Economics, Econom...|{\"field\":\"Social ...|no_idex|    École|   public|     Hôpital Beaujon|           Clichy|[{I4210097159, As...|      0|        0|     0|healthcare|            Medicine|{\"field\":\"Medicin...|          no_idex| undefined|   public|           0|      1|           0|      0|       1|      0|       1|      0|\n",
      "|       I57995698|   I2801279844|2020|    2|      4|     2| 0.20146520146520147|0.047619047619047616| 0.15384615384615385|           0|           4|           2|                  0|                  0|                    0|             0|             4|             0|                    0|                    0|                      0|            0|            0|            2|                   0|                   0|                     0|           0.0|0.047619047619047616|0.15384615384615385|                  0.0|                  0.0|                    0.0|             0.0|0.047619047619047616|                0.0|                    0.0|                    0.0|                      0.0|            0.0|                 0.0|0.15384615384615385|                   0.0|                   0.0|                     0.0|Paris School of E...| Paris|[{I57995698, Pari...|      0|        0|     1|education|Economics, Econom...|{\"field\":\"Social ...|no_idex|    École|   public|European Business...|            Paris|[{I2801279844, Eu...|      0|        0|     0| education|Business, Managem...|{\"field\":\"Economi...|          no_idex|     École|    privé|           0|      1|           0|      1|       1|      0|       0|      1|\n",
      "|       I57995698|   I2802331213|2020|    1|      0|     1|                 0.5|                 0.0|                 0.5|           0|           0|           1|                  0|                  1|                    0|             0|             0|             0|                    0|                    0|                      0|            0|            0|            1|                   0|                   1|                     0|           0.0|                 0.0|                0.5|                  0.0|                  0.5|                    0.0|             0.0|                 0.0|                0.0|                    0.0|                    0.0|                      0.0|            0.0|                 0.0|                0.5|                   0.0|                   0.5|                     0.0|Paris School of E...| Paris|[{I57995698, Pari...|      0|        0|     1|education|Economics, Econom...|{\"field\":\"Social ...|no_idex|    École|   public|Paris School of B...|            Paris|[{I2802331213, Pa...|      0|        0|     0| education|Economics, Econom...|{\"field\":\"Economi...|          no_idex|     École|    privé|           0|      1|           0|      1|       1|      0|       0|      1|\n",
      "|       I57995698|     I32448411|2020|    6|     18|     0|  1.1357142857142857|  1.1357142857142857|                 0.0|           0|          17|           1|                  6|                  3|                    5|             0|            17|             1|                    6|                    3|                      5|            0|            0|            0|                   0|                   0|                     0|           0.0|  0.8857142857142858|               0.25|  0.08571428571428572|  0.30000000000000004|                  0.625|             0.0|  0.8857142857142858|               0.25|    0.08571428571428572|    0.30000000000000004|                    0.625|            0.0|                 0.0|                0.0|                   0.0|                   0.0|                     0.0|Paris School of E...| Paris|[{I57995698, Pari...|      0|        0|     1|education|Economics, Econom...|{\"field\":\"Social ...|no_idex|    École|   public|Centre d'Etudes P...|            Paris|[{I32448411, Cent...|      0|        0|     0|  facility|Economics, Econom...|{\"field\":\"Social ...|          no_idex| undefined|undefined|           0|      1|           0|      0|       1|      0|       0|      0|\n",
      "|       I57995698|   I4210088826|2020|   21|     50|     2|   5.514603174603175|   4.403492063492065|  1.1111111111111112|           1|          39|          11|                  8|                  5|                   11|             0|            38|            11|                    7|                    4|                     10|            1|            1|            0|                   1|                   1|                     1|           1.0|  3.4368253968253972| 0.9666666666666666|    1.419047619047619|   1.9999999999999998|     2.5500000000000003|             0.0|   3.325714285714286| 0.9666666666666666|      0.419047619047619|                    1.0|       1.5499999999999998|            1.0|  0.1111111111111111|                0.0|                   1.0|                   1.0|                     1.0|Paris School of E...| Paris|[{I57995698, Pari...|      0|        0|     1|education|Economics, Econom...|{\"field\":\"Social ...|no_idex|    École|   public|Centre d'Économie...|            Paris|[{I4210150854, In...|      0|        1|     1|  facility|Economics, Econom...|{\"field\":\"Social ...|idex_paris_saclay|Université|   public|           0|      1|           1|      0|       1|      0|       1|      0|\n",
      "|       I57995698|   I4210092774|2020|    2|      0|     5| 0.15966386554621848|                 0.0| 0.15966386554621848|           0|           0|           2|                  0|                  0|                    0|             0|             0|             0|                    0|                    0|                      0|            0|            0|            2|                   0|                   0|                     0|           0.0|                 0.0|0.07142857142857142|                  0.0|                  0.0|                    0.0|             0.0|                 0.0|                0.0|                    0.0|                    0.0|                      0.0|            0.0|                 0.0|0.07142857142857142|                   0.0|                   0.0|                     0.0|Paris School of E...| Paris|[{I57995698, Pari...|      0|        0|     1|education|Economics, Econom...|{\"field\":\"Social ...|no_idex|    École|   public|      Hôpital Cochin|            Paris|[{I4210124464, Gr...|      0|        0|     0|healthcare|            Medicine|{\"field\":\"Medicin...|          no_idex| undefined|undefined|           0|      1|           0|      0|       1|      0|       0|      0|\n",
      "|       I57995698|   I4210099530|2020|    1|      4|     0|                 0.1|                 0.1|                 0.0|           0|           4|           0|                  0|                  0|                    0|             0|             4|             0|                    0|                    0|                      0|            0|            0|            0|                   0|                   0|                     0|           0.0|                 0.1|                0.0|                  0.0|                  0.0|                    0.0|             0.0|                 0.1|                0.0|                    0.0|                    0.0|                      0.0|            0.0|                 0.0|                0.0|                   0.0|                   0.0|                     0.0|Paris School of E...| Paris|[{I57995698, Pari...|      0|        0|     1|education|Economics, Econom...|{\"field\":\"Social ...|no_idex|    École|   public|IPAG Business School|            Paris|[{I4210099530, IP...|      0|        0|     0| education|Economics, Econom...|{\"field\":\"Economi...|          no_idex|     École|    privé|           0|      1|           0|      1|       1|      0|       0|      1|\n",
      "|       I57995698|   I4210101766|2020|    1|      0|     1|  0.3333333333333333|                 0.0|  0.3333333333333333|           0|           1|           0|                  0|                  0|                    0|             0|             0|             0|                    0|                    0|                      0|            0|            1|            0|                   0|                   0|                     0|           0.0|  0.3333333333333333|                0.0|                  0.0|                  0.0|                    0.0|             0.0|                 0.0|                0.0|                    0.0|                    0.0|                      0.0|            0.0|  0.3333333333333333|                0.0|                   0.0|                   0.0|                     0.0|Paris School of E...| Paris|[{I57995698, Pari...|      0|        0|     1|education|Economics, Econom...|{\"field\":\"Social ...|no_idex|    École|   public|Éditions Gallimar...|            Paris|[{I4210101766, Éd...|      0|        0|     0|   company|     Social Sciences|{\"field\":\"Social ...|          no_idex|     Firme|    privé|           0|      1|           0|      0|       1|      0|       0|      1|\n",
      "|       I57995698|   I4210102325|2020|    1|      0|     7| 0.06862745098039216|                 0.0| 0.06862745098039216|           0|           7|           0|                  0|                  0|                    0|             0|             0|             0|                    0|                    0|                      0|            0|            7|            0|                   0|                   0|                     0|           0.0| 0.06862745098039216|                0.0|                  0.0|                  0.0|                    0.0|             0.0|                 0.0|                0.0|                    0.0|                    0.0|                      0.0|            0.0| 0.06862745098039216|                0.0|                   0.0|                   0.0|                     0.0|Paris School of E...| Paris|[{I57995698, Pari...|      0|        0|     1|education|Economics, Econom...|{\"field\":\"Social ...|no_idex|    École|   public|Hôpital Européen ...|            Paris|[{I4210120235, Hô...|      0|        0|     0|healthcare|            Medicine|{\"field\":\"Medicin...|          no_idex| undefined|   public|           0|      1|           0|      0|       1|      0|       1|      0|\n",
      "|       I57995698|   I4210108912|2020|    1|      1|     0|                 0.5|                 0.5|                 0.0|           0|           1|           0|                  0|                  0|                    0|             0|             1|             0|                    0|                    0|                      0|            0|            0|            0|                   0|                   0|                     0|           0.0|                 0.5|                0.0|                  0.0|                  0.0|                    0.0|             0.0|                 0.5|                0.0|                    0.0|                    0.0|                      0.0|            0.0|                 0.0|                0.0|                   0.0|                   0.0|                     0.0|Paris School of E...| Paris|[{I57995698, Pari...|      0|        0|     1|education|Economics, Econom...|{\"field\":\"Social ...|no_idex|    École|   public|                CIEP|           Sèvres|[{I4210108912, CI...|      0|        0|     0| education|     Social Sciences|{\"field\":\"Social ...|          no_idex|     École|    privé|           0|      1|           0|      1|       1|      0|       0|      1|\n",
      "|       I57995698|   I4210109141|2020|    1|      0|     6|0.058823529411764705|                 0.0|0.058823529411764705|           0|           6|           0|                  0|                  0|                    0|             0|             0|             0|                    0|                    0|                      0|            0|            6|            0|                   0|                   0|                     0|           0.0|0.058823529411764705|                0.0|                  0.0|                  0.0|                    0.0|             0.0|                 0.0|                0.0|                    0.0|                    0.0|                      0.0|            0.0|0.058823529411764705|                0.0|                   0.0|                   0.0|                     0.0|Paris School of E...| Paris|[{I57995698, Pari...|      0|        0|     1|education|Economics, Econom...|{\"field\":\"Social ...|no_idex|    École|   public|    Hôpital Européen|        Marseille|[{I4210109141, Hô...|      0|        0|     0|healthcare|            Medicine|{\"field\":\"Medicin...|          no_idex| undefined|undefined|           0|      1|           0|      0|       1|      0|       0|      0|\n",
      "|       I57995698|   I4210113354|2020|    1|      2|     0|                0.25|                0.25|                 0.0|           0|           2|           0|                  0|                  0|                    0|             0|             2|             0|                    0|                    0|                      0|            0|            0|            0|                   0|                   0|                     0|           0.0|                0.25|                0.0|                  0.0|                  0.0|                    0.0|             0.0|                0.25|                0.0|                    0.0|                    0.0|                      0.0|            0.0|                 0.0|                0.0|                   0.0|                   0.0|                     0.0|Paris School of E...| Paris|[{I57995698, Pari...|      0|        0|     1|education|Economics, Econom...|{\"field\":\"Social ...|no_idex|    École|   public|   Economie Publique|Thiverval-Grignon|[{I22248866, Agro...|      0|        0|     0|  facility|Economics, Econom...|{\"field\":\"Social ...|idex_paris_saclay| undefined|   public|           0|      1|           0|      0|       1|      0|       1|      0|\n",
      "|       I57995698|   I4210114292|2020|    1|      0|     1|  0.3333333333333333|                 0.0|  0.3333333333333333|           0|           1|           0|                  0|                  0|                    1|             0|             0|             0|                    0|                    0|                      0|            0|            1|            0|                   0|                   0|                     1|           0.0|  0.3333333333333333|                0.0|                  0.0|                  0.0|     0.3333333333333333|             0.0|                 0.0|                0.0|                    0.0|                    0.0|                      0.0|            0.0|  0.3333333333333333|                0.0|                   0.0|                   0.0|      0.3333333333333333|Paris School of E...| Paris|[{I57995698, Pari...|      0|        0|     1|education|Economics, Econom...|{\"field\":\"Social ...|no_idex|    École|   public|Laboratoire d’Eco...|            Paris|[{I4210114292, La...|      0|        0|     0|  facility|     Social Sciences|{\"field\":\"Economi...|          no_idex| undefined|undefined|           0|      1|           0|      0|       1|      0|       0|      0|\n",
      "|       I57995698|   I4210120985|2020|    1|      1|     0|  0.3333333333333333|  0.3333333333333333|                 0.0|           0|           1|           0|                  0|                  0|                    1|             0|             1|             0|                    0|                    0|                      1|            0|            0|            0|                   0|                   0|                     0|           0.0|  0.3333333333333333|                0.0|                  0.0|                  0.0|     0.3333333333333333|             0.0|  0.3333333333333333|                0.0|                    0.0|                    0.0|       0.3333333333333333|            0.0|                 0.0|                0.0|                   0.0|                   0.0|                     0.0|Paris School of E...| Paris|[{I57995698, Pari...|      0|        0|     1|education|Economics, Econom...|{\"field\":\"Social ...|no_idex|    École|   public|Institut d'Histoi...|             Lyon|[{I1294671590, Ce...|      1|        1|     1|  facility| Arts and Humanities|{\"field\":\"Arts an...|idex_annulee_lyon|Université|   public|           0|      1|           1|      0|       1|      0|       1|      0|\n",
      "|       I57995698|   I4210121021|2020|    1|      2|     0|                0.25|                0.25|                 0.0|           0|           0|           2|                  0|                  2|                    0|             0|             0|             2|                    0|                    2|                      0|            0|            0|            0|                   0|                   0|                     0|           0.0|                 0.0|               0.25|                  0.0|                 0.25|                    0.0|             0.0|                 0.0|               0.25|                    0.0|                   0.25|                      0.0|            0.0|                 0.0|                0.0|                   0.0|                   0.0|                     0.0|Paris School of E...| Paris|[{I57995698, Pari...|      0|        0|     1|education|Economics, Econom...|{\"field\":\"Social ...|no_idex|    École|   public|Institut du Dével...|            Paris|[{I4210121021, In...|      0|        0|     0|     other|     Social Sciences|{\"field\":\"Social ...|          no_idex| undefined|undefined|           0|      1|           0|      0|       1|      0|       0|      0|\n",
      "|       I57995698|   I4210122952|2020|    1|      3|     0| 0.04285714285714286| 0.04285714285714286|                 0.0|           0|           3|           0|                  3|                  0|                    0|             0|             3|             0|                    3|                    0|                      0|            0|            0|            0|                   0|                   0|                     0|           0.0| 0.04285714285714286|                0.0|  0.04285714285714286|                  0.0|                    0.0|             0.0| 0.04285714285714286|                0.0|    0.04285714285714286|                    0.0|                      0.0|            0.0|                 0.0|                0.0|                   0.0|                   0.0|                     0.0|Paris School of E...| Paris|[{I57995698, Pari...|      0|        0|     1|education|Economics, Econom...|{\"field\":\"Social ...|no_idex|    École|   public|Maison des Scienc...|           Nantes|[{I4210122952, Ma...|      0|        0|     0|  facility|     Social Sciences|{\"field\":\"Social ...|          no_idex| undefined|   public|           0|      1|           0|      0|       1|      0|       1|      0|\n",
      "+----------------+--------------+----+-----+-------+------+--------------------+--------------------+--------------------+------------+------------+------------+-------------------+-------------------+---------------------+--------------+--------------+--------------+---------------------+---------------------+-----------------------+-------------+-------------+-------------+--------------------+--------------------+----------------------+--------------+--------------------+-------------------+---------------------+---------------------+-----------------------+----------------+--------------------+-------------------+-----------------------+-----------------------+-------------------------+---------------+--------------------+-------------------+----------------------+----------------------+------------------------+--------------------+------+--------------------+-------+---------+------+---------+--------------------+--------------------+-------+---------+---------+--------------------+-----------------+--------------------+-------+---------+------+----------+--------------------+--------------------+-----------------+----------+---------+------------+-------+------------+-------+--------+-------+--------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inst_level_flows.filter(func.col('inst_id_receiver')==\"I57995698\").filter(func.col('year')==\"2020\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "21731324-4bcb-41a1-bc2b-2ca3b0177dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+--------------------------------------------------------------------------+------+--------------------+\n",
      "|name_r                   |name_s                                                                    |movers|movers_w            |\n",
      "+-------------------------+--------------------------------------------------------------------------+------+--------------------+\n",
      "|Paris School of Economics|I4210103002                                                               |1     |0.04                |\n",
      "|Paris School of Economics|Alimentation et Sciences Sociales                                         |1     |0.5                 |\n",
      "|Paris School of Economics|Aix-Marseille Université                                                  |1     |0.0625              |\n",
      "|Paris School of Economics|Institut national d'études démographiques                                 |1     |0.5                 |\n",
      "|Paris School of Economics|Laboratoire Psychologie de la Perception                                  |1     |0.020833333333333332|\n",
      "|Paris School of Economics|Institut de Recherche sur les Systèmes Atomiques et Moléculaires Complexes|1     |0.06666666666666667 |\n",
      "|Paris School of Economics|Centre National de la Recherche Scientifique                              |4     |0.2263888888888889  |\n",
      "|Paris School of Economics|Centre d'Etudes Prospectives et d'Informations Internationales            |2     |0.10666666666666666 |\n",
      "|Paris School of Economics|Université Paris Cité                                                     |8     |0.9166666666666666  |\n",
      "|Paris School of Economics|Université Paris Dauphine-PSL                                             |1     |0.25                |\n",
      "|Paris School of Economics|Université Paris 1 Panthéon-Sorbonne                                      |5     |0.6152777777777778  |\n",
      "|Paris School of Economics|European Business School Paris                                            |1     |0.16666666666666666 |\n",
      "|Paris School of Economics|Université Clermont Auvergne                                              |1     |0.04                |\n",
      "|Paris School of Economics|Délégation Paris 5                                                        |2     |0.07638888888888888 |\n",
      "|Paris School of Economics|Institutions et Dynamiques Historiques de l'Économie et de la Société     |1     |0.16666666666666666 |\n",
      "|Paris School of Economics|Centre Pour La Recherche Economique et ses Applications                   |2     |0.6666666666666666  |\n",
      "|Paris School of Economics|Université Paris Nanterre                                                 |2     |0.20666666666666667 |\n",
      "|Paris School of Economics|École Polytechnique                                                       |1     |0.08333333333333333 |\n",
      "|Paris School of Economics|École Nationale de la Statistique et de l'Administration Économique       |1     |0.5                 |\n",
      "|Paris School of Economics|abroad                                                                    |37    |14.597222222222221  |\n",
      "|Paris School of Economics|Systèmes de Référence Temps-Espace                                        |1     |0.14285714285714285 |\n",
      "|Paris School of Economics|École de management de Lyon                                               |1     |0.05555555555555555 |\n",
      "|Paris School of Economics|Banque de France                                                          |7     |2.458333333333333   |\n",
      "|Paris School of Economics|EconomiX                                                                  |2     |0.10666666666666666 |\n",
      "|Paris School of Economics|École Normale Supérieure Paris-Saclay                                     |1     |0.0625              |\n",
      "|Paris School of Economics|École Normale Supérieure - PSL                                            |2     |0.2708333333333333  |\n",
      "|Paris School of Economics|Sorbonne Université                                                       |2     |0.31666666666666665 |\n",
      "|Paris School of Economics|Centre d'Économie de la Sorbonne                                          |9     |1.2125000000000001  |\n",
      "+-------------------------+--------------------------------------------------------------------------+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(inst_level_flows_moves\n",
    " .filter(func.col('inst_id_receiver')==\"x\")\n",
    " .filter(func.col('year')==2013)\n",
    " .withColumn('name_s', func.when(func.col('name_s').isNull(), func.col('inst_id_sender')).otherwise(func.col('name_s')))\n",
    " .select('name_r','name_s','movers','movers_w').filter('movers>0')).show(100,truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab3ba8d-4e1f-4b0f-a2f0-25b01eadfc9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ae0f77-811b-43e4-bc9f-849eb4985fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = (inst_level_flows_moves\n",
    "           .filter( (func.col('inst_id_receiver') != func.col('inst_id_sender')))\n",
    "           .filter(func.col('inst_id_sender')!=\"abroad\")\n",
    "           .groupBy('year','uni_pub_r')\n",
    "           .agg(func.sum('movers').alias('total_flow'),\n",
    "                func.mean('movers').alias('avg_flow'),\n",
    "                func.sum('total').alias('total'),\n",
    "                func.sum('movers_w').alias('total_flow_w'),\n",
    "                func.mean('movers_w').alias('avg_flow_w'),\n",
    "                func.sum('total_w').alias('total_w')\n",
    "               )\n",
    "          ).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcab560-f6e7-486c-bfe6-f0bdfa33d492",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_of_change = [2007]\n",
    "graph_3(to_plot[to_plot['year']>=1997], 'year','total_flow_w', 'uni_pub_r', [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5d8477-1798-4ec8-889f-30a04868534f",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_3(to_plot[to_plot['year']>=1997], 'year','avg_flow', 'uni_pub_r', [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcb39b7-a003-4b15-b465-642f3a1e42ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_3(to_plot[to_plot['year']>=1997], 'year','total_w', 'uni_pub_r', [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d8f8b9-a4fa-4701-8f08-4046ea2ff775",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = (inst_level_flows_moves\n",
    "           .filter( (func.col('inst_id_receiver') != func.col('inst_id_sender')))\n",
    "           .filter(func.col('inst_id_receiver')!=\"abroad\")\n",
    "           .filter(func.col('type_r')!=\"company\")\n",
    "           .groupBy('year','uni_pub_s')\n",
    "           .agg(func.sum('movers').alias('total_flow'),\n",
    "                func.mean('movers').alias('avg_flow'),\n",
    "                func.sum('total').alias('total'),\n",
    "                func.sum('movers_w').alias('total_flow_w'),\n",
    "                func.mean('movers_w').alias('avg_flow_w'),\n",
    "                func.sum('total_w').alias('total_w')\n",
    "               )\n",
    "          ).toPandas()\n",
    "graph_3(to_plot[to_plot['year']>=1997], 'year','total_flow_w', 'uni_pub_s', [0,1])\n",
    "graph_3(to_plot[to_plot['year']>=1997], 'year','avg_flow_w', 'uni_pub_s', [0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6073eef3-c269-4904-98e7-f15c7a04b110",
   "metadata": {},
   "source": [
    "# Lab-level output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3c7c041e-d06d-48d9-ba75-95f27011cb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------+--------------------+-----------+----+\n",
      "|inst_id_receiver|inst_id_sender|     inst_set_sender|  author_id|year|\n",
      "+----------------+--------------+--------------------+-----------+----+\n",
      "|     I4210098836|          NULL|                  []|A5000016899|1960|\n",
      "|     I4210152651|   I4210098836|       [I4210098836]|A5000016899|1964|\n",
      "|     I4210152651|   I4210152651|       [I4210152651]|A5000016899|1965|\n",
      "|     I4210152651|   I4210152651|[I4210152651, I10...|A5000016899|1966|\n",
      "|     I3020098449|   I4210152651|[I4210152651, I10...|A5000016899|1966|\n",
      "|     I4210152651|   I4210152651|[I4210152651, I30...|A5000016899|1967|\n",
      "|     I4210152651|   I3020098449|[I4210152651, I30...|A5000016899|1967|\n",
      "|      I100532134|   I4210152651|[I4210152651, I10...|A5000016899|1968|\n",
      "|     I4210152651|    I100532134|        [I100532134]|A5000016899|1969|\n",
      "|     I4210152651|   I4210152651|       [I4210152651]|A5000016899|1970|\n",
      "|     I4210144981|   I4210152651|       [I4210152651]|A5000016899|1972|\n",
      "|     I4210087136|   I4210144981|       [I4210144981]|A5000016899|2009|\n",
      "|     I4210158867|   I4210144981|       [I4210144981]|A5000016899|2009|\n",
      "|     I4210159650|   I4210144981|       [I4210144981]|A5000016899|2009|\n",
      "|     I4210128200|          NULL|                  []|A5000023309|2017|\n",
      "|       I48430043|          NULL|                  []|A5000087584|2018|\n",
      "|     I1294671590|          NULL|                  []|A5000087584|2018|\n",
      "|      I100532134|          NULL|                  []|A5000087584|2018|\n",
      "|     I1316868585|        abroad|            [abroad]|A5000139008|2020|\n",
      "|      I251321805|          NULL|                  []|A5000139201|2011|\n",
      "+----------------+--------------+--------------------+-----------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "au_inst_level_flow_filtering.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5f5c6e8-34c5-4ba8-80c2-ee9d1cb2801b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+-----------+--------------------+----------+---------+--------------------+------+------------+----------------+---------------+-----------+-------------------+---------------+\n",
      "|  author_id|year|    inst_id|     inst_set_sender|entry_year|exit_year|       entry_inst_id|stayer|first_y_inst|past_5_y_entrant|foreign_entrant|from_abroad|new_foreign_entrant|new_from_abroad|\n",
      "+-----------+----+-----------+--------------------+----------+---------+--------------------+------+------------+----------------+---------------+-----------+-------------------+---------------+\n",
      "|A5000016899|1968| I100532134|[I4210152651, I10...|      1960|     2009|       [I4210098836]|     1|        1968|               1|              0|          0|                  0|              0|\n",
      "|A5000016899|1966|I3020098449|[I4210152651, I10...|      1960|     2009|       [I4210098836]|     0|        1966|               1|              0|          0|                  0|              0|\n",
      "|A5000016899|2009|I4210087136|       [I4210144981]|      1960|     2009|       [I4210098836]|     0|        2009|               1|              0|          0|                  0|              0|\n",
      "|A5000016899|1960|I4210098836|                  []|      1960|     2009|       [I4210098836]|     0|        1960|               1|              0|          0|                  0|              0|\n",
      "|A5000016899|1972|I4210144981|       [I4210152651]|      1960|     2009|       [I4210098836]|     0|        1972|               1|              0|          0|                  0|              0|\n",
      "|A5000016899|1964|I4210152651|       [I4210098836]|      1960|     2009|       [I4210098836]|     0|        1964|               1|              0|          0|                  0|              0|\n",
      "|A5000016899|1965|I4210152651|       [I4210152651]|      1960|     2009|       [I4210098836]|     1|        1964|               1|              0|          0|                  0|              0|\n",
      "|A5000016899|1966|I4210152651|[I4210152651, I10...|      1960|     2009|       [I4210098836]|     1|        1964|               1|              0|          0|                  0|              0|\n",
      "|A5000016899|1967|I4210152651|[I4210152651, I30...|      1960|     2009|       [I4210098836]|     1|        1964|               1|              0|          0|                  0|              0|\n",
      "|A5000016899|1967|I4210152651|[I4210152651, I30...|      1960|     2009|       [I4210098836]|     1|        1964|               1|              0|          0|                  0|              0|\n",
      "|A5000016899|1969|I4210152651|        [I100532134]|      1960|     2009|       [I4210098836]|     0|        1964|               1|              0|          0|                  0|              0|\n",
      "|A5000016899|1970|I4210152651|       [I4210152651]|      1960|     2009|       [I4210098836]|     1|        1964|               0|              0|          0|                  0|              0|\n",
      "|A5000016899|2009|I4210158867|       [I4210144981]|      1960|     2009|       [I4210098836]|     0|        2009|               1|              0|          0|                  0|              0|\n",
      "|A5000016899|2009|I4210159650|       [I4210144981]|      1960|     2009|       [I4210098836]|     0|        2009|               1|              0|          0|                  0|              0|\n",
      "|A5000023309|2017|I4210128200|                  []|      2017|     2017|       [I4210128200]|     0|        2017|               1|              0|          0|                  0|              0|\n",
      "|A5000087584|2018| I100532134|                  []|      2018|     2018|[I100532134, I129...|     0|        2018|               1|              0|          0|                  0|              0|\n",
      "|A5000087584|2018|I1294671590|                  []|      2018|     2018|[I100532134, I129...|     0|        2018|               1|              0|          0|                  0|              0|\n",
      "|A5000087584|2018|  I48430043|                  []|      2018|     2018|[I100532134, I129...|     0|        2018|               1|              0|          0|                  0|              0|\n",
      "|A5000139008|2020|I1316868585|            [abroad]|      1993|     2020|            [abroad]|     0|        2020|               1|              1|          1|                  1|              1|\n",
      "|A5000139201|2011| I131077856|                  []|      2011|     2013|[I131077856, I251...|     0|        2011|               1|              0|          0|                  0|              0|\n",
      "+-----------+----+-----------+--------------------+----------+---------+--------------------+------+------------+----------------+---------------+-----------+-------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w_for_lags = Window.partitionBy('inst_id','author_id').orderBy('year')\n",
    "\n",
    "au_inst_y = (au_inst_level_plus_info\n",
    "               .select('author_id','year', func.col('inst_id_receiver').alias('inst_id'), 'inst_set_sender', 'entry_year', 'exit_year','entry_inst_id')\n",
    "             .withColumn('stayer', (func.array_contains(func.col('inst_set_sender'), func.col('inst_id'))  ).cast('int'))\n",
    "             .withColumn('first_y_inst', func.min('year').over(Window.partitionBy('author_id','inst_id')))\n",
    "             .withColumn('past_5_y_entrant', func.greatest(\n",
    "                        1-func.col('stayer'), (func.col('year')-func.col('first_y_inst') <=5).cast('int')  ))\n",
    "             .withColumn('foreign_entrant', (func.array_contains(func.col('entry_inst_id'),('abroad')) ).cast('int'))\n",
    "             .withColumn('from_abroad', func.max((func.col('inst_set_sender')==func.array([func.lit('abroad')])).cast('int')).over(Window.partitionBy('author_id','inst_id')))\n",
    "             .withColumn('new_foreign_entrant', func.col('foreign_entrant')*func.col('past_5_y_entrant'))\n",
    "             .withColumn('new_from_abroad', func.col('from_abroad')*func.col('past_5_y_entrant'))\n",
    "            )\n",
    "au_inst_y.cache()\n",
    "au_inst_y.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeab42fb-3c7b-4e32-af37-45c580427396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39569c06-8f3a-4623-88de-72cf10f03941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2269979e-ed9f-4167-8486-1c0aec528b82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ec6285c-0b5b-4676-9c9d-6486013d0819",
   "metadata": {},
   "outputs": [],
   "source": [
    "au_inst_y.write.mode('overwrite').parquet('file:\\\\' + int_save_path + 'au_inst_y_step_3.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96f61b00-0c76-4129-9f04-72b92fc1ae6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "au_inst_y = spark.read.parquet('file:\\\\' + int_save_path + 'au_inst_y_step_3.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07f210d2-86c5-4252-80dc-335b8f71baa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1503432"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "au_to_select = au_inst_y.select('author_id').distinct()\n",
    "au_to_select.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9e52a99-38ba-4891-bdaf-bc84c5d78f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10448409"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "au_inst_y.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7695a747-8704-48ae-8375-62270f96aef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[inst_id: string, year: int, all_5_y: array<string>, all_5_y_abroad: array<string>, all_5_y_foreign_entrants: array<string>, all_authors_y: array<string>, total: bigint]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inst_y = (au_inst_y\n",
    "          .groupBy('inst_id','year')\n",
    "          .agg(        \n",
    "               func.array_compact(\n",
    "                        func.collect_set(func.when(func.col('past_5_y_entrant')==1, func.col('author_id')))).alias('all_5_y'),\n",
    "               func.array_compact(\n",
    "                        func.collect_set(func.when(func.col('new_from_abroad')==1, func.col('author_id')))).alias('all_5_y_abroad'),\n",
    "               func.array_compact(\n",
    "                        func.collect_set(func.when(func.col('new_foreign_entrant')==1, func.col('author_id')))).alias('all_5_y_foreign_entrants'),\n",
    "\n",
    "              func.collect_set(func.col('author_id')).alias('all_authors_y'),\n",
    "               func.count('author_id').alias('total')\n",
    "              )\n",
    "         )\n",
    "inst_y.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f62cbdf-ade0-4201-b1cb-e63fd0f1a599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94641"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inst_y.count() #94641"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbc81728-aff8-411f-8781-d5c8f7889638",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+--------------------+--------------------+------------------------+--------------------+-----+\n",
      "|    inst_id|year|             all_5_y|      all_5_y_abroad|all_5_y_foreign_entrants|       all_authors_y|total|\n",
      "+-----------+----+--------------------+--------------------+------------------------+--------------------+-----+\n",
      "| I106530797|1996|[A5014014363, A50...|                  []|                      []|[A5014014363, A50...|    3|\n",
      "| I112936343|2006|[A5088701076, A50...|[A5004952249, A50...|                      []|[A5063958148, A50...|  213|\n",
      "| I117345614|1995|[A5065129513, A50...|       [A5006144861]|                      []|[A5065129513, A50...|    3|\n",
      "|  I11935315|2020|[A5082738725, A50...|[A5082738725, A51...|                      []|[A5082738725, A50...|   53|\n",
      "|  I12449238|1999|[A5049460103, A50...|[A5050665658, A50...|                      []|[A5049530006, A50...|  264|\n",
      "| I126425946|1990|       [A5000339680]|                  []|                      []|       [A5000339680]|    1|\n",
      "|I1288051870|1999|[A5097635055, A50...|[A5064971353, A50...|                      []|[A5097635055, A50...|  111|\n",
      "|I1297213882|2012|       [A5001545243]|                  []|                      []|       [A5001545243]|    1|\n",
      "|I1316868585|2015|[A5033721382, A50...|[A5033721382, A50...|                      []|[A5033721382, A50...|   22|\n",
      "|I1326498283|1995|[A5037132841, A50...|[A5037132841, A50...|                      []|[A5037132841, A50...|  391|\n",
      "| I137725305|1987|       [A5050245658]|                  []|                      []|       [A5050245658]|    1|\n",
      "| I142179503|1998|[A5094634740, A50...|                  []|                      []|[A5094634740, A50...|    4|\n",
      "| I142476485|1986|[A5048031838, A51...|[A5054003346, A50...|                      []|[A5048031838, A51...|  312|\n",
      "| I149758196|2000|[A5059694696, A50...|[A5075105418, A50...|                      []|[A5059694696, A50...|  358|\n",
      "|  I15057530|2019|[A5099424915, A50...|[A5000045670, A51...|                      []|[A5099424915, A50...| 2095|\n",
      "| I158447531|2017|[A5040670076, A50...|[A5084975322, A50...|                      []|[A5040670076, A50...|   25|\n",
      "| I169645620|2002|[A5067727795, A50...|[A5074705294, A51...|                      []|[A5011078090, A50...|  772|\n",
      "| I174424907|1992|[A5056232610, A50...|[A5045670125, A50...|                      []|[A5056232610, A50...|   19|\n",
      "| I177064439|1996|[A5067887023, A50...|[A5023468345, A50...|                      []|[A5067887023, A50...|  479|\n",
      "| I181418319|2014|[A5036020445, A50...|[A5024663654, A50...|                      []|[A5036020445, A50...|  102|\n",
      "+-----------+----+--------------------+--------------------+------------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inst_y.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd4a7de6-bcc7-455e-b915-512870fc82b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8316075"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inst_y.withColumn('author_id', func.explode(\"all_authors_y\")).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77fff1f9-01df-4ee2-95fe-6fc80750964e",
   "metadata": {},
   "outputs": [],
   "source": [
    "works_subset = (works_au_af.select('author_id','work_id')\n",
    "                      .join(au_to_select, on = 'author_id')  \n",
    "                .select('work_id').distinct()\n",
    "                     )\n",
    "works_subset.write.mode('overwrite').parquet('file:\\\\' + int_save_path + 'works_subset_for_labs.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3385276d-a214-4688-bba9-46ff65a05767",
   "metadata": {},
   "outputs": [],
   "source": [
    "works_subset= spark.read.parquet('file:\\\\' + int_save_path + 'works_subset_for_labs.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a4e8e7f-3c8e-444a-950b-f9dbc260441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "works_au_af_subset = (works_au_af\n",
    "                      .select('work_id','publication_year','author_id','source_id','citations','primary_topic')\n",
    "                      .join(works_subset, on = 'work_id')                      \n",
    "                      .groupBy('work_id')\n",
    "                      .agg(func.first('publication_year').alias('year'),\n",
    "                           *[func.first(col).alias(col) for col in ['source_id','citations','primary_topic']],\n",
    "                           func.collect_set('author_id').alias('all_author_id'))\n",
    "                      #.withColumn('author_id', func.explode(func.col('all_author_id')))\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b960d19-4346-4dcd-a62b-0fc63fba57ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "works_au_af_subset.write.mode('overwrite').parquet('file:\\\\' + int_save_path + 'works_subset_for_labs_w_info.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3e63764-08ca-4537-905b-cb2430c56e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "works_au_af_subset = spark.read.parquet('file:\\\\' + int_save_path + 'works_subset_for_labs_w_info.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddba4d95-b3f7-49eb-a32e-f4d144530929",
   "metadata": {},
   "outputs": [],
   "source": [
    "au_coau_y = (works_au_af_subset\n",
    "                      .withColumn('author_id', func.explode(\"all_author_id\"))\n",
    "                      .groupBy('author_id','year')\n",
    "                      .agg(func.array_compact(func.flatten(func.collect_set('all_author_id'))).alias('coau_set'))\n",
    "            )\n",
    "au_coau_y.write.mode('overwrite').parquet('file:\\\\' + int_save_path + 'au_coau_y_for_labs.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26ffda28-f267-40f9-838f-8d6d1a252bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+--------------------+\n",
      "|  author_id|year|            coau_set|\n",
      "+-----------+----+--------------------+\n",
      "|A5000000264|2000|[A5089850702, A50...|\n",
      "|A5000000404|2002|[A5052219169, A50...|\n",
      "|A5000001517|2012|[A5041323441, A50...|\n",
      "|A5000001860|1994|[A5000001860, A50...|\n",
      "|A5000002667|2001|[A5039926783, A51...|\n",
      "|A5000003527|1991|[A5005858959, A50...|\n",
      "|A5000003667|2013|[A5102007451, A50...|\n",
      "|A5000004035|2019|[A5043565899, A50...|\n",
      "|A5000004186|2003|[A5019186997, A50...|\n",
      "|A5000004202|1997|[A5019155815, A50...|\n",
      "|A5000004315|2009|[A5066629896, A50...|\n",
      "|A5000004520|2016|[A5059582543, A50...|\n",
      "|A5000004589|2018|[A5000004589, A50...|\n",
      "|A5000005289|1990|[A5027609347, A50...|\n",
      "|A5000005390|1979|[A5009916482, A50...|\n",
      "|A5000005548|2015|[A5041832372, A50...|\n",
      "|A5000005898|2018|[A5026289654, A50...|\n",
      "|A5000005998|2010|[A5075148303, A50...|\n",
      "|A5000006247|2020|[A5004298766, A50...|\n",
      "|A5000006452|1998|[A5079332858, A50...|\n",
      "+-----------+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "au_coau_y= spark.read.parquet('file:\\\\' + int_save_path + 'au_coau_y_for_labs.parquet')\n",
    "au_coau_y.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f76b48b-486f-4309-8ef5-e315fb34f6a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67221348"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "au_coau_y.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68929047-2165-4caa-9881-da8250bec1cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o181.parquet.\n: org.apache.spark.SparkException: Job 19 cancelled \r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:2731)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3013)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 10\u001b[0m\n\u001b[0;32m      1\u001b[0m inst_work_au \u001b[38;5;241m=\u001b[39m (inst_y\n\u001b[0;32m      2\u001b[0m                 \u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthor_id\u001b[39m\u001b[38;5;124m'\u001b[39m, func\u001b[38;5;241m.\u001b[39mexplode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall_authors_y\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      3\u001b[0m                 \u001b[38;5;241m.\u001b[39mjoin(works_au_af_subset\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m                       on \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthor_id\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m], how \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m                )\n\u001b[1;32m---> 10\u001b[0m \u001b[43minst_work_au\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moverwrite\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfile:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mint_save_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minst_work_au.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\pyspark\\sql\\readwriter.py:1721\u001b[0m, in \u001b[0;36mDataFrameWriter.parquet\u001b[1;34m(self, path, mode, partitionBy, compression)\u001b[0m\n\u001b[0;32m   1719\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartitionBy(partitionBy)\n\u001b[0;32m   1720\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(compression\u001b[38;5;241m=\u001b[39mcompression)\n\u001b[1;32m-> 1721\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o181.parquet.\n: org.apache.spark.SparkException: Job 19 cancelled \r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:2731)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3013)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n"
     ]
    }
   ],
   "source": [
    "inst_work_au = (inst_y\n",
    "                .withColumn('author_id', func.explode(\"all_authors_y\"))\n",
    "                .join(works_au_af_subset\n",
    "                      .withColumn('author_id', func.explode(\"all_author_id\"))\n",
    "                      .drop('all_author_id'),\n",
    "                      on  = ['author_id','year'], how = 'left')\n",
    "                .join(au_coau_y,\n",
    "                      on = ['author_id','year'], how = 'left')\n",
    "               )\n",
    "inst_work_au.write.mode('overwrite').parquet('file:\\\\' + int_save_path + 'inst_work_au.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b1857cf-57b6-4404-b67a-3dcec3b4d089",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o161.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 7 in stage 27.0 failed 1 times, most recent failure: Lost task 7.0 in stage 27.0 (TID 620) (CDF-9FB1674.priv.college-de-france.fr executor driver): java.lang.OutOfMemoryError: Java heap space\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\nCaused by: java.lang.OutOfMemoryError: Java heap space\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m inst_work_au\u001b[38;5;241m.\u001b[39mcache()\n\u001b[1;32m----> 2\u001b[0m \u001b[43minst_work_au\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\pyspark\\sql\\dataframe.py:947\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow\u001b[39m(\u001b[38;5;28mself\u001b[39m, n: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, truncate: Union[\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, vertical: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    888\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Prints the first ``n`` rows to the console.\u001b[39;00m\n\u001b[0;32m    889\u001b[0m \n\u001b[0;32m    890\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[38;5;124;03m    name | Bob\u001b[39;00m\n\u001b[0;32m    946\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_show_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\pyspark\\sql\\dataframe.py:965\u001b[0m, in \u001b[0;36mDataFrame._show_string\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[0;32m    960\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    961\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(vertical)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[0;32m    962\u001b[0m     )\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[1;32m--> 965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    967\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o161.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 7 in stage 27.0 failed 1 times, most recent failure: Lost task 7.0 in stage 27.0 (TID 620) (CDF-9FB1674.priv.college-de-france.fr executor driver): java.lang.OutOfMemoryError: Java heap space\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\nCaused by: java.lang.OutOfMemoryError: Java heap space\r\n"
     ]
    }
   ],
   "source": [
    "inst_work_au.cache()\n",
    "inst_work_au.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "934bed40-896c-4787-ba9e-2b61a66133ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py\", line 179, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\py4j\\protocol.py\", line 326, in get_return_value\n",
      "    raise Py4JJavaError(\n",
      "py4j.protocol.Py4JJavaError: <exception str() failed>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\py4j\\clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\socket.py\", line 716, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "ConnectionResetError: [WinError 10054] Une connexion existante a dû être fermée par l’hôte distant\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\py4j\\java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\py4j\\clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "py4j does not exist in the JVM",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31m<class 'str'>\u001b[0m: (<class 'ConnectionRefusedError'>, ConnectionRefusedError(10061, 'Aucune connexion n’a pu être établie car l’ordinateur cible l’a expressément refusée', None, 10061, None))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 19\u001b[0m\n\u001b[0;32m      1\u001b[0m inst_work_level \u001b[38;5;241m=\u001b[39m (inst_work_au\n\u001b[0;32m      2\u001b[0m                     \u001b[38;5;241m.\u001b[39mjoin(journals_ranking, on \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource_id\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m], how \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m                     \u001b[38;5;241m.\u001b[39mgroupBy(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minst_id\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwork_id\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m                   )\n\u001b[0;32m     18\u001b[0m inst_work_level\u001b[38;5;241m.\u001b[39mcache()\n\u001b[1;32m---> 19\u001b[0m \u001b[43minst_work_level\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\pyspark\\sql\\dataframe.py:947\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow\u001b[39m(\u001b[38;5;28mself\u001b[39m, n: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, truncate: Union[\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, vertical: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    888\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Prints the first ``n`` rows to the console.\u001b[39;00m\n\u001b[0;32m    889\u001b[0m \n\u001b[0;32m    890\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[38;5;124;03m    name | Bob\u001b[39;00m\n\u001b[0;32m    946\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_show_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\pyspark\\sql\\dataframe.py:965\u001b[0m, in \u001b[0;36mDataFrame._show_string\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[0;32m    960\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    961\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(vertical)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[0;32m    962\u001b[0m     )\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[1;32m--> 965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    967\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:181\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 181\u001b[0m     converted \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava_exception\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    183\u001b[0m         \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    184\u001b[0m         \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m    185\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:141\u001b[0m, in \u001b[0;36mconvert_exception\u001b[1;34m(e)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_instance_of(gw, e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjava.lang.NumberFormatException\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NumberFormatException(origin\u001b[38;5;241m=\u001b[39me)\n\u001b[1;32m--> 141\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[43mis_instance_of\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjava.lang.IllegalArgumentException\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m IllegalArgumentException(origin\u001b[38;5;241m=\u001b[39me)\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_instance_of(gw, e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjava.lang.ArithmeticException\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\py4j\\java_gateway.py:464\u001b[0m, in \u001b[0;36mis_instance_of\u001b[1;34m(gateway, java_object, java_class)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    462\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjava_class must be a string, a JavaClass, or a JavaObject\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 464\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgateway\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpy4j\u001b[49m\u001b[38;5;241m.\u001b[39mreflection\u001b[38;5;241m.\u001b[39mTypeUtil\u001b[38;5;241m.\u001b[39misInstanceOf(\n\u001b[0;32m    465\u001b[0m     param, java_object)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\py4j\\java_gateway.py:1725\u001b[0m, in \u001b[0;36mJVMView.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1722\u001b[0m _, error_message \u001b[38;5;241m=\u001b[39m get_error_message(answer)\n\u001b[0;32m   1723\u001b[0m message \u001b[38;5;241m=\u001b[39m compute_exception_message(\n\u001b[0;32m   1724\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m does not exist in the JVM\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name), error_message)\n\u001b[1;32m-> 1725\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(message)\n",
      "\u001b[1;31mPy4JError\u001b[0m: py4j does not exist in the JVM"
     ]
    }
   ],
   "source": [
    "inst_work_level = (inst_work_au\n",
    "                    .join(journals_ranking, on = ['source_id','year'], how = 'left')\n",
    "                    .groupBy('inst_id','work_id','year')\n",
    "                    .agg(*[func.first(col).alias(col) for col in ['citations', 'rank_source_pct']],\n",
    "                         *[func.max( (func.array_contains(func.col(cat_col),func.col('author_id'))).cast('int') ).alias('is_' + cat_col)\n",
    "                           for cat_col in ['all_5_y','all_5_y_abroad', 'all_5_y_foreign_entrants']],\n",
    "                         *[func.max( ((func.arrays_overlap(func.col('coau_set'), func.col(cat_col)))\n",
    "                                    & (~func.array_contains(func.col(cat_col),func.col('author_id'))) ).cast('int')\n",
    "                                   ).alias('is_coau_' + cat_col)\n",
    "                           for cat_col in ['all_5_y','all_5_y_abroad', 'all_5_y_foreign_entrants']],\n",
    "                         *[func.max( ((~func.arrays_overlap(func.col('coau_set'), func.col(cat_col)))\n",
    "                                    & (~func.array_contains(func.col(cat_col),func.col('author_id'))) ).cast('int')\n",
    "                                   ).alias('is_no_coau_' + cat_col)\n",
    "                           for cat_col in ['all_5_y','all_5_y_abroad', 'all_5_y_foreign_entrants']]\n",
    "                        )\n",
    "\n",
    "                  )\n",
    "inst_work_level.cache()\n",
    "inst_work_level.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb5d9af-99a5-4a22-b8eb-39e18c595fda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3545707b-f853-4575-93ee-5a08ae473873",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o382.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 36 in stage 57.0 failed 1 times, most recent failure: Lost task 36.0 in stage 57.0 (TID 2903) (CDF-9FB1674.priv.college-de-france.fr executor driver): java.lang.OutOfMemoryError: Java heap space\r\n\tat org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder.grow(BufferHolder.java:80)\r\n\tat org.apache.spark.sql.catalyst.expressions.codegen.UnsafeWriter.grow(UnsafeWriter.java:63)\r\n\tat org.apache.spark.sql.catalyst.expressions.codegen.UnsafeWriter.writeUnalignedBytes(UnsafeWriter.java:127)\r\n\tat org.apache.spark.sql.catalyst.expressions.codegen.UnsafeWriter.write(UnsafeWriter.java:110)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anon$1.next(WindowExec.scala:198)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anon$1.next(WindowExec.scala:107)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$1772/0x0000000800d60840.apply(Unknown Source)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\r\n\tat java.base/java.lang.Thread.run(Thread.java:829)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\nCaused by: java.lang.OutOfMemoryError: Java heap space\r\n\tat org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder.grow(BufferHolder.java:80)\r\n\tat org.apache.spark.sql.catalyst.expressions.codegen.UnsafeWriter.grow(UnsafeWriter.java:63)\r\n\tat org.apache.spark.sql.catalyst.expressions.codegen.UnsafeWriter.writeUnalignedBytes(UnsafeWriter.java:127)\r\n\tat org.apache.spark.sql.catalyst.expressions.codegen.UnsafeWriter.write(UnsafeWriter.java:110)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anon$1.next(WindowExec.scala:198)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anon$1.next(WindowExec.scala:107)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$1772/0x0000000800d60840.apply(Unknown Source)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\r\n\tat java.base/java.lang.Thread.run(Thread.java:829)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m au_y_coau \u001b[38;5;241m=\u001b[39m (au_inst_level_plus_info\n\u001b[0;32m      2\u001b[0m              \u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthor_id\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdistinct()\n\u001b[0;32m      3\u001b[0m              \u001b[38;5;241m.\u001b[39mjoin(works_au_af\u001b[38;5;241m.\u001b[39mfilter(func\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpublication_year\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mbetween(\u001b[38;5;241m1980\u001b[39m,\u001b[38;5;241m2020\u001b[39m))\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m                    , on \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthor_id\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m             )\n\u001b[0;32m      8\u001b[0m au_y_coau\u001b[38;5;241m.\u001b[39mcache()\n\u001b[1;32m----> 9\u001b[0m \u001b[43mau_y_coau\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\pyspark\\sql\\dataframe.py:947\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow\u001b[39m(\u001b[38;5;28mself\u001b[39m, n: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, truncate: Union[\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, vertical: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    888\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Prints the first ``n`` rows to the console.\u001b[39;00m\n\u001b[0;32m    889\u001b[0m \n\u001b[0;32m    890\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[38;5;124;03m    name | Bob\u001b[39;00m\n\u001b[0;32m    946\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_show_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\pyspark\\sql\\dataframe.py:965\u001b[0m, in \u001b[0;36mDataFrame._show_string\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[0;32m    960\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    961\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(vertical)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[0;32m    962\u001b[0m     )\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[1;32m--> 965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    967\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o382.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 36 in stage 57.0 failed 1 times, most recent failure: Lost task 36.0 in stage 57.0 (TID 2903) (CDF-9FB1674.priv.college-de-france.fr executor driver): java.lang.OutOfMemoryError: Java heap space\r\n\tat org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder.grow(BufferHolder.java:80)\r\n\tat org.apache.spark.sql.catalyst.expressions.codegen.UnsafeWriter.grow(UnsafeWriter.java:63)\r\n\tat org.apache.spark.sql.catalyst.expressions.codegen.UnsafeWriter.writeUnalignedBytes(UnsafeWriter.java:127)\r\n\tat org.apache.spark.sql.catalyst.expressions.codegen.UnsafeWriter.write(UnsafeWriter.java:110)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anon$1.next(WindowExec.scala:198)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anon$1.next(WindowExec.scala:107)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$1772/0x0000000800d60840.apply(Unknown Source)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\r\n\tat java.base/java.lang.Thread.run(Thread.java:829)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\nCaused by: java.lang.OutOfMemoryError: Java heap space\r\n\tat org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder.grow(BufferHolder.java:80)\r\n\tat org.apache.spark.sql.catalyst.expressions.codegen.UnsafeWriter.grow(UnsafeWriter.java:63)\r\n\tat org.apache.spark.sql.catalyst.expressions.codegen.UnsafeWriter.writeUnalignedBytes(UnsafeWriter.java:127)\r\n\tat org.apache.spark.sql.catalyst.expressions.codegen.UnsafeWriter.write(UnsafeWriter.java:110)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anon$1.next(WindowExec.scala:198)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anon$1.next(WindowExec.scala:107)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$1772/0x0000000800d60840.apply(Unknown Source)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\r\n\tat java.base/java.lang.Thread.run(Thread.java:829)\r\n"
     ]
    }
   ],
   "source": [
    "au_y_coau = (au_inst_level_plus_info\n",
    "             .select('author_id').distinct()\n",
    "             .join(works_au_af.filter(func.col('publication_year').between(1980,2020))\n",
    "                      .withColumn('coau_set', func.collect_set(func.col('author_id')).over(Window.partitionBy('publication_year')))\n",
    "                   .select('coau_set','author_id', func.col('publication_year').alias('year'))\n",
    "                   , on = 'author_id', how= 'left')\n",
    "            )\n",
    "au_y_coau.cache()\n",
    "au_y_coau.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4c15f7-d779-48fb-9878-44b1a1deb6dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54c23957-ff7a-4edc-8d81-0eb1058872a2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o437.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 131 in stage 66.0 failed 1 times, most recent failure: Lost task 131.0 in stage 66.0 (TID 2731) (CDF-9FB1674.priv.college-de-france.fr executor driver): java.lang.OutOfMemoryError: Java heap space\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\nCaused by: java.lang.OutOfMemoryError: Java heap space\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m works_subset \u001b[38;5;241m=\u001b[39m (works_au_af\n\u001b[0;32m      2\u001b[0m                    \u001b[38;5;241m.\u001b[39mfilter(func\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpublication_year\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mbetween(\u001b[38;5;241m1980\u001b[39m,\u001b[38;5;241m2020\u001b[39m))\n\u001b[0;32m      3\u001b[0m                      \u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthor_id\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwork_id\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpublication_year\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcitations\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource_id\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m                 \u001b[38;5;241m.\u001b[39mjoin(au_inst_level_plus_info\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthor_id\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdistinct(), on \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthor_id\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m                       \u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoau_set\u001b[39m\u001b[38;5;124m'\u001b[39m, func\u001b[38;5;241m.\u001b[39mcollect_set(func\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthor_id\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39mover(Window\u001b[38;5;241m.\u001b[39mpartitionBy(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpublication_year\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[0;32m      6\u001b[0m                )\n\u001b[0;32m      7\u001b[0m works_subset\u001b[38;5;241m.\u001b[39mcache()\n\u001b[1;32m----> 8\u001b[0m \u001b[43mworks_subset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\pyspark\\sql\\dataframe.py:947\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow\u001b[39m(\u001b[38;5;28mself\u001b[39m, n: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, truncate: Union[\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, vertical: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    888\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Prints the first ``n`` rows to the console.\u001b[39;00m\n\u001b[0;32m    889\u001b[0m \n\u001b[0;32m    890\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[38;5;124;03m    name | Bob\u001b[39;00m\n\u001b[0;32m    946\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_show_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\pyspark\\sql\\dataframe.py:965\u001b[0m, in \u001b[0;36mDataFrame._show_string\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[0;32m    960\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    961\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(vertical)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[0;32m    962\u001b[0m     )\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[1;32m--> 965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    967\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o437.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 131 in stage 66.0 failed 1 times, most recent failure: Lost task 131.0 in stage 66.0 (TID 2731) (CDF-9FB1674.priv.college-de-france.fr executor driver): java.lang.OutOfMemoryError: Java heap space\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\nCaused by: java.lang.OutOfMemoryError: Java heap space\r\n"
     ]
    }
   ],
   "source": [
    "works_subset = (works_au_af\n",
    "                   .filter(func.col('publication_year').between(1980,2020))\n",
    "                     .select('author_id','work_id','publication_year','citations','source_id')\n",
    "                .join(au_inst_level_plus_info.select('author_id').distinct(), on ='author_id')\n",
    "               )\n",
    "works_subset.cache()\n",
    "works_subset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cab5de44-7923-47b7-975f-bd8d509a6683",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o545.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 5 in stage 98.0 failed 1 times, most recent failure: Lost task 5.0 in stage 98.0 (TID 3757) (CDF-9FB1674.priv.college-de-france.fr executor driver): java.lang.OutOfMemoryError: Java heap space\r\n\tat org.apache.spark.unsafe.types.UTF8String.fromAddress(UTF8String.java:132)\r\n\tat org.apache.spark.sql.catalyst.expressions.UnsafeRow.getUTF8String(UnsafeRow.java:382)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)\r\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$.$anonfun$prepareShuffleDependency$6(ShuffleExchangeExec.scala:323)\r\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$.$anonfun$prepareShuffleDependency$6$adapted(ShuffleExchangeExec.scala:323)\r\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$$Lambda$3892/0x0000000801818840.apply(Unknown Source)\r\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$.$anonfun$prepareShuffleDependency$14(ShuffleExchangeExec.scala:392)\r\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$$Lambda$3932/0x000000080183d040.apply(Unknown Source)\r\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:169)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$1767/0x0000000800d5dc40.apply(Unknown Source)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\r\n\tat java.base/java.lang.Thread.run(Thread.java:829)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\nCaused by: java.lang.OutOfMemoryError: Java heap space\r\n\tat org.apache.spark.unsafe.types.UTF8String.fromAddress(UTF8String.java:132)\r\n\tat org.apache.spark.sql.catalyst.expressions.UnsafeRow.getUTF8String(UnsafeRow.java:382)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)\r\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$.$anonfun$prepareShuffleDependency$6(ShuffleExchangeExec.scala:323)\r\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$.$anonfun$prepareShuffleDependency$6$adapted(ShuffleExchangeExec.scala:323)\r\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$$Lambda$3892/0x0000000801818840.apply(Unknown Source)\r\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$.$anonfun$prepareShuffleDependency$14(ShuffleExchangeExec.scala:392)\r\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$$Lambda$3932/0x000000080183d040.apply(Unknown Source)\r\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:169)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$1767/0x0000000800d5dc40.apply(Unknown Source)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\r\n\tat java.base/java.lang.Thread.run(Thread.java:829)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 23\u001b[0m\n\u001b[0;32m      1\u001b[0m inst_work_level \u001b[38;5;241m=\u001b[39m (works_subset\n\u001b[0;32m      2\u001b[0m                       \u001b[38;5;241m.\u001b[39mwithColumnRenamed(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpublication_year\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m                       \u001b[38;5;241m.\u001b[39mjoin(journals_ranking, on \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource_id\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m], how \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m \n\u001b[0;32m     21\u001b[0m                   )\n\u001b[0;32m     22\u001b[0m inst_work_level\u001b[38;5;241m.\u001b[39mcache()\n\u001b[1;32m---> 23\u001b[0m \u001b[43minst_work_level\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\pyspark\\sql\\dataframe.py:947\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow\u001b[39m(\u001b[38;5;28mself\u001b[39m, n: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, truncate: Union[\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, vertical: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    888\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Prints the first ``n`` rows to the console.\u001b[39;00m\n\u001b[0;32m    889\u001b[0m \n\u001b[0;32m    890\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[38;5;124;03m    name | Bob\u001b[39;00m\n\u001b[0;32m    946\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_show_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\pyspark\\sql\\dataframe.py:965\u001b[0m, in \u001b[0;36mDataFrame._show_string\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[0;32m    960\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    961\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(vertical)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[0;32m    962\u001b[0m     )\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[1;32m--> 965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    967\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o545.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 5 in stage 98.0 failed 1 times, most recent failure: Lost task 5.0 in stage 98.0 (TID 3757) (CDF-9FB1674.priv.college-de-france.fr executor driver): java.lang.OutOfMemoryError: Java heap space\r\n\tat org.apache.spark.unsafe.types.UTF8String.fromAddress(UTF8String.java:132)\r\n\tat org.apache.spark.sql.catalyst.expressions.UnsafeRow.getUTF8String(UnsafeRow.java:382)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)\r\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$.$anonfun$prepareShuffleDependency$6(ShuffleExchangeExec.scala:323)\r\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$.$anonfun$prepareShuffleDependency$6$adapted(ShuffleExchangeExec.scala:323)\r\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$$Lambda$3892/0x0000000801818840.apply(Unknown Source)\r\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$.$anonfun$prepareShuffleDependency$14(ShuffleExchangeExec.scala:392)\r\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$$Lambda$3932/0x000000080183d040.apply(Unknown Source)\r\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:169)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$1767/0x0000000800d5dc40.apply(Unknown Source)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\r\n\tat java.base/java.lang.Thread.run(Thread.java:829)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\nCaused by: java.lang.OutOfMemoryError: Java heap space\r\n\tat org.apache.spark.unsafe.types.UTF8String.fromAddress(UTF8String.java:132)\r\n\tat org.apache.spark.sql.catalyst.expressions.UnsafeRow.getUTF8String(UnsafeRow.java:382)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)\r\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$.$anonfun$prepareShuffleDependency$6(ShuffleExchangeExec.scala:323)\r\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$.$anonfun$prepareShuffleDependency$6$adapted(ShuffleExchangeExec.scala:323)\r\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$$Lambda$3892/0x0000000801818840.apply(Unknown Source)\r\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$.$anonfun$prepareShuffleDependency$14(ShuffleExchangeExec.scala:392)\r\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$$Lambda$3932/0x000000080183d040.apply(Unknown Source)\r\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:169)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$1767/0x0000000800d5dc40.apply(Unknown Source)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\r\n\tat java.base/java.lang.Thread.run(Thread.java:829)\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inst_work_level = (works_subset\n",
    "                      .withColumnRenamed('publication_year','year')\n",
    "                      .join(journals_ranking, on = ['source_id','year'], how = 'left')\n",
    "                      .join(inst_y\n",
    "                            .withColumn('author_id', func.explode(\"all_authors_y\")), on = ['author_id','year'], how = 'inner')\n",
    "                    .groupBy('inst_id','work_id','year')\n",
    "                    .agg(*[func.first(col).alias(col) for col in ['citations', 'rank_source_pct']],\n",
    "                         *[func.max( (func.array_contains(func.col(cat_col),func.col('author_id'))).cast('int') ).alias('is_' + cat_col)\n",
    "                           for cat_col in ['all_5_y','all_5_y_abroad', 'all_5_y_foreign_entrants']],\n",
    "                         *[func.max( ((func.arrays_overlap(func.col('coau_set'), func.col(cat_col)))\n",
    "                                    & (~func.array_contains(func.col(cat_col),func.col('author_id'))) ).cast('int')\n",
    "                                   ).alias('is_coau_' + cat_col)\n",
    "                           for cat_col in ['all_5_y','all_5_y_abroad', 'all_5_y_foreign_entrants']],\n",
    "                         *[func.max( ((~func.arrays_overlap(func.col('coau_set'), func.col(cat_col)))\n",
    "                                    & (~func.array_contains(func.col(cat_col),func.col('author_id'))) ).cast('int')\n",
    "                                   ).alias('is_no_coau_' + cat_col)\n",
    "                           for cat_col in ['all_5_y','all_5_y_abroad', 'all_5_y_foreign_entrants']]\n",
    "                        )\n",
    "\n",
    "                  )\n",
    "inst_work_level.cache()\n",
    "inst_work_level.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d27b2ad2-d329-40a7-980a-b51dc8e42b21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o5082.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 585 in stage 431.0 failed 1 times, most recent failure: Lost task 585.0 in stage 431.0 (TID 11793) (CDF-9FB1674.priv.college-de-france.fr executor driver): java.lang.OutOfMemoryError: Java heap space\r\n\tat java.base/java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:61)\r\n\tat java.base/java.nio.ByteBuffer.allocate(ByteBuffer.java:348)\r\n\tat org.apache.parquet.bytes.HeapByteBufferAllocator.allocate(HeapByteBufferAllocator.java:32)\r\n\tat org.apache.parquet.hadoop.ParquetFileReader$ConsecutivePartList.readAll(ParquetFileReader.java:1846)\r\n\tat org.apache.parquet.hadoop.ParquetFileReader.internalReadRowGroup(ParquetFileReader.java:990)\r\n\tat org.apache.parquet.hadoop.ParquetFileReader.readNextRowGroup(ParquetFileReader.java:940)\r\n\tat org.apache.parquet.hadoop.ParquetFileReader.readNextFilteredRowGroup(ParquetFileReader.java:1100)\r\n\tat org.apache.spark.sql.execution.datasources.parquet.SpecificParquetRecordReaderBase$ParquetRowGroupReaderImpl.readNextRowGroup(SpecificParquetRecordReaderBase.java:287)\r\n\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.checkEndOfRowGroup(VectorizedParquetRecordReader.java:418)\r\n\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.nextBatch(VectorizedParquetRecordReader.java:335)\r\n\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.nextKeyValue(VectorizedParquetRecordReader.java:233)\r\n\tat org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:129)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:283)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:129)\r\n\tat org.apache.spark.sql.execution.FileSourceScanExec$$anon$1.hasNext(DataSourceScanExec.scala:593)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.columnartorow_nextBatch_0$(Unknown Source)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$1774/0x0000000800d61040.apply(Unknown Source)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\nCaused by: java.lang.OutOfMemoryError: Java heap space\r\n\tat java.base/java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:61)\r\n\tat java.base/java.nio.ByteBuffer.allocate(ByteBuffer.java:348)\r\n\tat org.apache.parquet.bytes.HeapByteBufferAllocator.allocate(HeapByteBufferAllocator.java:32)\r\n\tat org.apache.parquet.hadoop.ParquetFileReader$ConsecutivePartList.readAll(ParquetFileReader.java:1846)\r\n\tat org.apache.parquet.hadoop.ParquetFileReader.internalReadRowGroup(ParquetFileReader.java:990)\r\n\tat org.apache.parquet.hadoop.ParquetFileReader.readNextRowGroup(ParquetFileReader.java:940)\r\n\tat org.apache.parquet.hadoop.ParquetFileReader.readNextFilteredRowGroup(ParquetFileReader.java:1100)\r\n\tat org.apache.spark.sql.execution.datasources.parquet.SpecificParquetRecordReaderBase$ParquetRowGroupReaderImpl.readNextRowGroup(SpecificParquetRecordReaderBase.java:287)\r\n\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.checkEndOfRowGroup(VectorizedParquetRecordReader.java:418)\r\n\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.nextBatch(VectorizedParquetRecordReader.java:335)\r\n\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.nextKeyValue(VectorizedParquetRecordReader.java:233)\r\n\tat org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:129)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:283)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:129)\r\n\tat org.apache.spark.sql.execution.FileSourceScanExec$$anon$1.hasNext(DataSourceScanExec.scala:593)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.columnartorow_nextBatch_0$(Unknown Source)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$1774/0x0000000800d61040.apply(Unknown Source)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[89], line 62\u001b[0m\n\u001b[0;32m      3\u001b[0m inst_level_output \u001b[38;5;241m=\u001b[39m (works_au_af\n\u001b[0;32m      4\u001b[0m                      \u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minst_id\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m                       \u001b[38;5;241m.\u001b[39mwithColumnRenamed(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpublication_year\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     59\u001b[0m                         )\n\u001b[0;32m     60\u001b[0m                    )\n\u001b[0;32m     61\u001b[0m inst_level_output\u001b[38;5;241m.\u001b[39mcache()\n\u001b[1;32m---> 62\u001b[0m \u001b[43minst_level_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\pyspark\\sql\\dataframe.py:947\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow\u001b[39m(\u001b[38;5;28mself\u001b[39m, n: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, truncate: Union[\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, vertical: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    888\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Prints the first ``n`` rows to the console.\u001b[39;00m\n\u001b[0;32m    889\u001b[0m \n\u001b[0;32m    890\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[38;5;124;03m    name | Bob\u001b[39;00m\n\u001b[0;32m    946\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_show_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\pyspark\\sql\\dataframe.py:965\u001b[0m, in \u001b[0;36mDataFrame._show_string\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[0;32m    960\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    961\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(vertical)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[0;32m    962\u001b[0m     )\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[1;32m--> 965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    967\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o5082.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 585 in stage 431.0 failed 1 times, most recent failure: Lost task 585.0 in stage 431.0 (TID 11793) (CDF-9FB1674.priv.college-de-france.fr executor driver): java.lang.OutOfMemoryError: Java heap space\r\n\tat java.base/java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:61)\r\n\tat java.base/java.nio.ByteBuffer.allocate(ByteBuffer.java:348)\r\n\tat org.apache.parquet.bytes.HeapByteBufferAllocator.allocate(HeapByteBufferAllocator.java:32)\r\n\tat org.apache.parquet.hadoop.ParquetFileReader$ConsecutivePartList.readAll(ParquetFileReader.java:1846)\r\n\tat org.apache.parquet.hadoop.ParquetFileReader.internalReadRowGroup(ParquetFileReader.java:990)\r\n\tat org.apache.parquet.hadoop.ParquetFileReader.readNextRowGroup(ParquetFileReader.java:940)\r\n\tat org.apache.parquet.hadoop.ParquetFileReader.readNextFilteredRowGroup(ParquetFileReader.java:1100)\r\n\tat org.apache.spark.sql.execution.datasources.parquet.SpecificParquetRecordReaderBase$ParquetRowGroupReaderImpl.readNextRowGroup(SpecificParquetRecordReaderBase.java:287)\r\n\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.checkEndOfRowGroup(VectorizedParquetRecordReader.java:418)\r\n\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.nextBatch(VectorizedParquetRecordReader.java:335)\r\n\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.nextKeyValue(VectorizedParquetRecordReader.java:233)\r\n\tat org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:129)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:283)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:129)\r\n\tat org.apache.spark.sql.execution.FileSourceScanExec$$anon$1.hasNext(DataSourceScanExec.scala:593)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.columnartorow_nextBatch_0$(Unknown Source)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$1774/0x0000000800d61040.apply(Unknown Source)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\nCaused by: java.lang.OutOfMemoryError: Java heap space\r\n\tat java.base/java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:61)\r\n\tat java.base/java.nio.ByteBuffer.allocate(ByteBuffer.java:348)\r\n\tat org.apache.parquet.bytes.HeapByteBufferAllocator.allocate(HeapByteBufferAllocator.java:32)\r\n\tat org.apache.parquet.hadoop.ParquetFileReader$ConsecutivePartList.readAll(ParquetFileReader.java:1846)\r\n\tat org.apache.parquet.hadoop.ParquetFileReader.internalReadRowGroup(ParquetFileReader.java:990)\r\n\tat org.apache.parquet.hadoop.ParquetFileReader.readNextRowGroup(ParquetFileReader.java:940)\r\n\tat org.apache.parquet.hadoop.ParquetFileReader.readNextFilteredRowGroup(ParquetFileReader.java:1100)\r\n\tat org.apache.spark.sql.execution.datasources.parquet.SpecificParquetRecordReaderBase$ParquetRowGroupReaderImpl.readNextRowGroup(SpecificParquetRecordReaderBase.java:287)\r\n\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.checkEndOfRowGroup(VectorizedParquetRecordReader.java:418)\r\n\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.nextBatch(VectorizedParquetRecordReader.java:335)\r\n\tat org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.nextKeyValue(VectorizedParquetRecordReader.java:233)\r\n\tat org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:129)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:283)\r\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:129)\r\n\tat org.apache.spark.sql.execution.FileSourceScanExec$$anon$1.hasNext(DataSourceScanExec.scala:593)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.columnartorow_nextBatch_0$(Unknown Source)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$1774/0x0000000800d61040.apply(Unknown Source)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "inst_level_output = (inst_work_level\n",
    "                    .groupBy('inst_id','year')\n",
    "                    .agg(func.countDistinct('work_id').alias('publications'),\n",
    "                         func.sum('citations').alias('citations'),\n",
    "                         func.mean('rank_source_pct').alias('avg_rank_source_pct'), \n",
    "                         func.sum('rank_source_pct').alias('rank_w_publications'),\n",
    "                         func.sum((func.col('rank_source_pct')<= 0.5).cast('int')).alias('nr_source_btm_50pct'),\n",
    "                         func.sum((func.col('rank_source_pct').between(0.5,0.9)).cast('int')).alias('nr_source_mid_40pct'),\n",
    "                         func.sum((func.col('rank_source_pct')>= 0.8).cast('int')).alias('nr_source_top_20pct'),\n",
    "                         func.sum((func.col('rank_source_pct')>= 0.9).cast('int')).alias('nr_source_top_10pct'),\n",
    "                         func.sum((func.col('rank_source_pct')>= 0.95).cast('int')).alias('nr_source_top_5pct'),\n",
    "                         func.sum((func.col('rank_source_pct')>= 0.99).cast('int')).alias('nr_source_top_1pct'),\n",
    "\n",
    "                         *[ func.sum(cat_coau + cat_new).alias(cat_coau.replace('is','publications')+cat_new) \n",
    "                           for cat_coau, cat_new in product(['is_','is_coau_','is_no_coau_'], ['all_5_y','all_5_y_abroad', 'all_5_y_foreign_entrants'])],\n",
    "                         *[ func.sum(func.col(cat_coau + cat_new)*func.col('citations') ).alias(cat_coau.replace('is','citations')+cat_new) \n",
    "                           for cat_coau, cat_new in product(['is_','is_coau_','is_no_coau_'], ['all_5_y','all_5_y_abroad', 'all_5_y_foreign_entrants'])],\n",
    "                         *[ func.sum(func.col(cat_coau + cat_new)*func.col('rank_source_pct') ).alias(cat_coau.replace('is','rank_w_pub')+cat_new) \n",
    "                           for cat_coau, cat_new in product(['is_','is_coau_','is_no_coau_'], ['all_5_y','all_5_y_abroad', 'all_5_y_foreign_entrants'])],\n",
    "                         *[ func.mean(func.col(cat_coau + cat_new)*func.col('rank_source_pct') ).alias(cat_coau.replace('is','avg_rank')+cat_new) \n",
    "                           for cat_coau, cat_new in product(['is_','is_coau_','is_no_coau_'], ['all_5_y','all_5_y_abroad', 'all_5_y_foreign_entrants'])],\n",
    "                         *[ func.sum(func.col(cat_coau + cat_new)*(func.col('rank_source_pct')<= 0.5).cast('int') ).alias(cat_coau.replace('is','nr_source_btm_50pct')+cat_new) \n",
    "                           for cat_coau, cat_new in product(['is_','is_coau_','is_no_coau_'], ['all_5_y','all_5_y_abroad', 'all_5_y_foreign_entrants'])],\n",
    "                         *[ func.sum(func.col(cat_coau + cat_new)*(func.col('rank_source_pct').between(0.5,0.9)).cast('int')).alias(cat_coau.replace('is','nr_source_mid_40pct')+cat_new) \n",
    "                           for cat_coau, cat_new in product(['is_','is_coau_','is_no_coau_'], ['all_5_y','all_5_y_abroad', 'all_5_y_foreign_entrants'])],\n",
    "                         *[ func.sum(func.col(cat_coau + cat_new)*(func.col('rank_source_pct')>= 0.8).cast('int') ).alias(cat_coau.replace('is','nr_source_top_20pct')+cat_new) \n",
    "                           for cat_coau, cat_new in product(['is_','is_coau_','is_no_coau_'], ['all_5_y','all_5_y_abroad', 'all_5_y_foreign_entrants'])],\n",
    "                         *[ func.sum(func.col(cat_coau + cat_new)*(func.col('rank_source_pct')>= 0.9).cast('int') ).alias(cat_coau.replace('is','nr_source_top_10pct')+cat_new) \n",
    "                           for cat_coau, cat_new in product(['is_','is_coau_','is_no_coau_'], ['all_5_y','all_5_y_abroad', 'all_5_y_foreign_entrants'])],\n",
    "                         *[ func.sum(func.col(cat_coau + cat_new)*(func.col('rank_source_pct')>= 0.95).cast('int') ).alias(cat_coau.replace('is','nr_source_top_5pct')+cat_new) \n",
    "                           for cat_coau, cat_new in product(['is_','is_coau_','is_no_coau_'], ['all_5_y','all_5_y_abroad', 'all_5_y_foreign_entrants'])],\n",
    "                         *[ func.sum(func.col(cat_coau + cat_new)*(func.col('rank_source_pct')>= 0.99).cast('int') ).alias(cat_coau.replace('is','nr_source_top_1pct')+cat_new) \n",
    "                           for cat_coau, cat_new in product(['is_','is_coau_','is_no_coau_'], ['all_5_y','all_5_y_abroad', 'all_5_y_foreign_entrants'])],\n",
    "\n",
    "\n",
    "                        )\n",
    "                   )\n",
    "inst_level_output.cache()\n",
    "inst_level_output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163c353b-6981-4669-9cf7-c51675d1231d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f68a8d4-3ac4-41ee-8737-d2dbb387d68d",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o1226.parquet.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 13 in stage 43.0 failed 1 times, most recent failure: Lost task 13.0 in stage 43.0 (TID 2765) (CDF-9FB1674.priv.college-de-france.fr executor driver): java.lang.OutOfMemoryError: Java heap space\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\nCaused by: java.lang.OutOfMemoryError: Java heap space\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mlab_level_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moverwrite\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfile:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlab_level_output.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\pyspark\\sql\\readwriter.py:1721\u001b[0m, in \u001b[0;36mDataFrameWriter.parquet\u001b[1;34m(self, path, mode, partitionBy, compression)\u001b[0m\n\u001b[0;32m   1719\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartitionBy(partitionBy)\n\u001b[0;32m   1720\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(compression\u001b[38;5;241m=\u001b[39mcompression)\n\u001b[1;32m-> 1721\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o1226.parquet.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 13 in stage 43.0 failed 1 times, most recent failure: Lost task 13.0 in stage 43.0 (TID 2765) (CDF-9FB1674.priv.college-de-france.fr executor driver): java.lang.OutOfMemoryError: Java heap space\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\nCaused by: java.lang.OutOfMemoryError: Java heap space\r\n"
     ]
    }
   ],
   "source": [
    "inst_level_output.write.mode('overwrite').parquet('file:\\\\' + save_path + 'lab_level_output.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8e4243-3849-4713-bb45-91b7cb92676a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
