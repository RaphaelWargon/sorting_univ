{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd86e9da-5a1b-4f35-b574-b1f0f810ba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import time\n",
    "from itertools import cycle, islice\n",
    "#from transformers import pipeline, AutoModel, AutoModelForSequenceClassification,AutoTokenizer\n",
    "import findspark\n",
    "findspark.init('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
<<<<<<< Updated upstream
=======
   "id": "3c0fa55f-04f2-4083-b949-5a4f2cd2ea61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CDF-9FB1674\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "hostname = print(socket.gethostname())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
>>>>>>> Stashed changes
   "id": "1596101f-1804-4df9-9d4a-e98decab7402",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m##### SET UP PATHS\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m base_path_code \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mopenalex-snapshot\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      6\u001b[0m     databases_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mopenalex-snapshot\u001b[39m\u001b[38;5;124m'\u001b[39m \n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "##### SET UP PATHS\n",
    "\n",
    "base_path_code = os.path.abspath(\"\").replace('headers','')\n",
    "\n",
    "if os.path.exists('E:\\\\openalex-snapshot'):\n",
    "    databases_path = 'E:\\\\openalex-snapshot' \n",
    "    scanR_path =  'E:\\\\scanR' \n",
    "    spark_temp_dir = 'E:\\\\spark-temp'\n",
    "elif os.path.exists('D:\\\\openalex-snapshot'):\n",
    "    databases_path = 'D:\\\\openalex-snapshot'\n",
    "    spark_temp_dir = 'D:\\\\spark-temp'\n",
    "    scanR_path =  'D:\\\\scanR' \n",
    "elif os.path.exists('F:\\\\openalex-snapshot'):\n",
    "    databases_path = 'F:\\\\openalex-snapshot'\n",
    "    spark_temp_dir = 'F:\\\\spark-temp'\n",
    "    scanR_path =  'F:\\\\scanR' \n",
    "else:\n",
    "    print('No hard drive detected')\n",
    "    databases_path = 'C:\\\\Users\\\\rapha\\\\Desktop\\\\'\n",
    "    scanR_path= databases_path\n",
    "    spark_temp_dir = 'C:\\\\Users\\\\rapha\\\\AppData\\\\Local\\\\Temp'\n",
    "\n",
    "main_path_openalex = databases_path + '\\\\data_extracted\\\\'\n",
    "works_au_af_path = main_path_openalex + 'works_au_af.parquet'\n",
    "references_path = main_path_openalex + 'references.parquet'\n",
    "output_path = databases_path\n",
    "save_path = scanR_path.replace(\"scanR\", \"panel_fr_res\") + '\\\\'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27ab2d6-7990-4005-a605-23526c1ff35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(app_name)\n",
    "except:\n",
    "    app_name = 'default'\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as func\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType,ArrayType,BooleanType\n",
    "import sparknlp\n",
    "import time \n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "\n",
    "from pyspark.ml import Pipeline,PipelineModel\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "if hostname == \"CDF-9FB1674\":\n",
    "    print('starting spark-nlp session')\n",
    "    spark = sparknlp.start(app_name, gpu = True)\n",
    "\n",
    "else:\n",
    "    print('starting spark session')\n",
    "    spark = SparkSession.builder \\\n",
    "                        .config(\"spark.sql.debug.maxToStringFields\", 1000)\\\n",
    "                        .config(\"spark.sql.files.maxPartitionBytes\", str(160 * 1024 * 1024)+\"b\")\\\n",
    "                        .config(\"spark.executor.memory\", \"20g\")\\\n",
    "                        .config(\"spark.driver.memory\", \"20g\")\\\n",
    "                        .config('spark.executor.cores',4) \\\n",
    "                        .config(\n",
    "        \"spark.driver.extraJavaOptions\",\n",
    "        \"--add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED\",\n",
    "    ) \\\n",
    "                        .master(\"local[*]\") \\\n",
    "                        .config(\"spark.local.dir\", spark_temp_dir)\\\n",
    "                        .appName(app_name) \\\n",
    "                        .getOrCreate()\n",
    "                        #.enableHiveSupport()\\\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dd2eff-d069-4be9-88a3-803dcf82b211",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns \n",
    "import matplotlib as mlt\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle, islice\n",
    "\n",
    "SINGLE_PLOT_SIZE=(10,8)\n",
    "\n",
    "def graph_2(df, x, y):\n",
    "    sns.set_theme(style='white')\n",
    "    fig,ax=plt.subplots(1,figsize=SINGLE_PLOT_SIZE)\n",
    "    sns.lineplot(\n",
    "        data=df,\n",
    "        x=x, y=y, \n",
    "        legend = False,\n",
    "        estimator = None\n",
    "    )\n",
    "    #plt.axvline(2018, color=\"firebrick\", linestyle='--',linewidth = 0.75)\n",
    "    #plt.axvline(2015, color=\"darkseagreen\", linestyle='--',linewidth = 0.75)\n",
    "      # Background color\n",
    "    fig.set_facecolor(\"white\")\n",
    "      # Y-axis\n",
    "    current_values = plt.gca().get_yticks()\n",
    "    plt.gca().set_yticklabels([round(x, 4) for x in current_values])\n",
    "    plt.ylabel('', fontsize=14,loc='center',labelpad=10)\n",
    "\n",
    "    # X-axis\n",
    "    plt.xlabel('Year', fontsize=14,loc='center',labelpad=10)\n",
    "\n",
    "    # Title\n",
    "    #fig.suptitle(col_dict_titles[y], fontsize=14)\n",
    "     \n",
    "    fig.suptitle(y, fontsize=14)\n",
    "\n",
    "    for year in year_of_change:\n",
    "        plt.axvline(year, color=\"firebrick\", linestyle='--', linewidth=0.75)\n",
    "    # Box\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "      # Legend\n",
    "    plt.legend(\n",
    "        loc='lower center', \n",
    "        bbox_to_anchor=(0.5,-0.43),\n",
    "    )\n",
    "    fig.tight_layout()\n",
    "    \n",
    "\n",
    "def graph_3(df, x, y, categorical, values_cat):\n",
    "    sns.set_theme(style='white')\n",
    "    custom_colors = ['seagreen', 'steelblue', \"darkseagreen\", 'lightsteelblue','midnightblue','grey','goldenrod','burlywood','peru']\n",
    "    fig,ax=plt.subplots(1,figsize=SINGLE_PLOT_SIZE)\n",
    "    sns.lineplot(\n",
    "        data=df,\n",
    "        x=x, y=y, hue = categorical,\n",
    "        palette = ['firebrick'] +list(islice(cycle(custom_colors), None, len(values_cat)-1)),\n",
    "        legend = False,\n",
    "        estimator = None\n",
    "    )\n",
    "    #plt.axvline(2018, color=\"firebrick\", linestyle='--',linewidth = 0.75)\n",
    "    #plt.axvline(2015, color=\"darkseagreen\", linestyle='--',linewidth = 0.75)\n",
    "      # Background color\n",
    "    fig.set_facecolor(\"white\")\n",
    "      # Y-axis\n",
    "    current_values = plt.gca().get_yticks()\n",
    "    plt.gca().set_yticklabels([round(x, 4) for x in current_values])\n",
    "    plt.ylabel('', fontsize=14,loc='center',labelpad=10)\n",
    "\n",
    "    # X-axis\n",
    "    plt.xlabel('Year', fontsize=14,loc='center',labelpad=10)\n",
    "\n",
    "    # Title\n",
    "    #fig.suptitle(col_dict_titles[y], fontsize=14)\n",
    "     \n",
    "    fig.suptitle(y, fontsize=14)\n",
    "\n",
    "    for year in year_of_change:\n",
    "        plt.axvline(year, color=\"firebrick\", linestyle='--', linewidth=0.75)\n",
    "    # Box\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "      # Legend\n",
    "    plt.legend(\n",
    "        loc='lower center', \n",
    "        bbox_to_anchor=(0.5,-0.43),\n",
    "        ncol=3,\n",
    "        labels = values_cat\n",
    "    )\n",
    "    fig.tight_layout()\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
