{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd86e9da-5a1b-4f35-b574-b1f0f810ba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import time\n",
    "from itertools import cycle, islice\n",
    "from transformers import pipeline, AutoModel, AutoModelForSequenceClassification,AutoTokenizer\n",
    "import findspark\n",
    "findspark.init('')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
<<<<<<< HEAD
<<<<<<< Updated upstream
=======
   "id": "3c0fa55f-04f2-4083-b949-5a4f2cd2ea61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CDF-9FB1674\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "hostname = print(socket.gethostname())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
>>>>>>> Stashed changes
=======
   "execution_count": null,
>>>>>>> parent of c878191 (update_merge_panel)
=======
>>>>>>> parent of c7a76a3 (update_fe_and_panel)
   "id": "1596101f-1804-4df9-9d4a-e98decab7402",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### SET UP PATHS\n",
    "\n",
    "base_path_code = os.path.abspath(\"\").replace('headers','')\n",
    "\n",
    "if os.path.exists('E:\\\\openalex-snapshot'):\n",
    "    databases_path = 'E:\\\\openalex-snapshot' \n",
    "    scanR_path =  'E:\\\\scanR' \n",
    "    spark_temp_dir = 'E:\\\\spark-temp'\n",
    "elif os.path.exists('D:\\\\openalex-snapshot'):\n",
    "    databases_path = 'D:\\\\openalex-snapshot'\n",
    "    spark_temp_dir = 'D:\\\\spark-temp'\n",
    "    scanR_path =  'D:\\\\scanR' \n",
    "elif os.path.exists('F:\\\\openalex-snapshot'):\n",
    "    databases_path = 'F:\\\\openalex-snapshot'\n",
    "    spark_temp_dir = 'F:\\\\spark-temp'\n",
    "    scanR_path =  'F:\\\\scanR' \n",
    "else:\n",
    "    print('No hard drive detected')\n",
    "    spark_temp_dir = 'C:\\\\Users\\\\rapha\\\\AppData\\\\Local\\\\Temp'\n",
    "\n",
    "main_path_openalex = databases_path + '\\\\data_extracted\\\\'\n",
    "works_au_af_path = main_path_openalex + 'works_au_af.parquet'\n",
    "references_path = main_path_openalex + 'references.parquet'\n",
    "output_path = databases_path\n",
    "save_path = scanR_path.replace(\"scanR\", \"panel_fr_res\") + '\\\\'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27ab2d6-7990-4005-a605-23526c1ff35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(app_name)\n",
    "except:\n",
    "    app_name = 'default'\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as func\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType,ArrayType,BooleanType\n",
    "spark = SparkSession.builder \\\n",
    "                    .config(\"spark.sql.debug.maxToStringFields\", 1000)\\\n",
    "                    .config(\"spark.sql.files.maxPartitionBytes\", str(160 * 1024 * 1024)+\"b\")\\\n",
    "                    .config(\"spark.executor.memory\", \"20g\")\\\n",
    "                    .config(\"spark.driver.memory\", \"20g\")\\\n",
    "                    .config('spark.executor.cores',4) \\\n",
    "                    .config(\n",
    "    \"spark.driver.extraJavaOptions\",\n",
    "    \"--add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED\",\n",
    ") \\\n",
    "                    .master(\"local[*]\") \\\n",
    "                    .config(\"spark.local.dir\", spark_temp_dir)\\\n",
    "                    .appName(app_name) \\\n",
    "                    .getOrCreate()\n",
    "                    #.enableHiveSupport()\\\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dd2eff-d069-4be9-88a3-803dcf82b211",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns \n",
    "import matplotlib as mlt\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle, islice\n",
    "\n",
    "SINGLE_PLOT_SIZE=(10,8)\n",
    "\n",
    "def graph_2(df, x, y):\n",
    "    sns.set_theme(style='white')\n",
    "    fig,ax=plt.subplots(1,figsize=SINGLE_PLOT_SIZE)\n",
    "    sns.lineplot(\n",
    "        data=df,\n",
    "        x=x, y=y, \n",
    "        legend = False,\n",
    "        estimator = None\n",
    "    )\n",
    "    #plt.axvline(2018, color=\"firebrick\", linestyle='--',linewidth = 0.75)\n",
    "    #plt.axvline(2015, color=\"darkseagreen\", linestyle='--',linewidth = 0.75)\n",
    "      # Background color\n",
    "    fig.set_facecolor(\"white\")\n",
    "      # Y-axis\n",
    "    current_values = plt.gca().get_yticks()\n",
    "    plt.gca().set_yticklabels([round(x, 4) for x in current_values])\n",
    "    plt.ylabel('', fontsize=14,loc='center',labelpad=10)\n",
    "\n",
    "    # X-axis\n",
    "    plt.xlabel('Year', fontsize=14,loc='center',labelpad=10)\n",
    "\n",
    "    # Title\n",
    "    #fig.suptitle(col_dict_titles[y], fontsize=14)\n",
    "     \n",
    "    fig.suptitle(y, fontsize=14)\n",
    "\n",
    "    for year in year_of_change:\n",
    "        plt.axvline(year, color=\"firebrick\", linestyle='--', linewidth=0.75)\n",
    "    # Box\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "      # Legend\n",
    "    plt.legend(\n",
    "        loc='lower center', \n",
    "        bbox_to_anchor=(0.5,-0.43),\n",
    "    )\n",
    "    fig.tight_layout()\n",
    "    \n",
    "\n",
    "def graph_3(df, x, y, categorical, values_cat):\n",
    "    sns.set_theme(style='white')\n",
    "    custom_colors = ['seagreen', 'steelblue', \"darkseagreen\", 'lightsteelblue','midnightblue','grey','goldenrod','burlywood','peru']\n",
    "    fig,ax=plt.subplots(1,figsize=SINGLE_PLOT_SIZE)\n",
    "    sns.lineplot(\n",
    "        data=df,\n",
    "        x=x, y=y, hue = categorical,\n",
    "        palette = ['firebrick'] +list(islice(cycle(custom_colors), None, len(values_cat)-1)),\n",
    "        legend = False,\n",
    "        estimator = None\n",
    "    )\n",
    "    #plt.axvline(2018, color=\"firebrick\", linestyle='--',linewidth = 0.75)\n",
    "    #plt.axvline(2015, color=\"darkseagreen\", linestyle='--',linewidth = 0.75)\n",
    "      # Background color\n",
    "    fig.set_facecolor(\"white\")\n",
    "      # Y-axis\n",
    "    current_values = plt.gca().get_yticks()\n",
    "    plt.gca().set_yticklabels([round(x, 4) for x in current_values])\n",
    "    plt.ylabel('', fontsize=14,loc='center',labelpad=10)\n",
    "\n",
    "    # X-axis\n",
    "    plt.xlabel('Year', fontsize=14,loc='center',labelpad=10)\n",
    "\n",
    "    # Title\n",
    "    #fig.suptitle(col_dict_titles[y], fontsize=14)\n",
    "     \n",
    "    fig.suptitle(y, fontsize=14)\n",
    "\n",
    "    for year in year_of_change:\n",
    "        plt.axvline(year, color=\"firebrick\", linestyle='--', linewidth=0.75)\n",
    "    # Box\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "      # Legend\n",
    "    plt.legend(\n",
    "        loc='lower center', \n",
    "        bbox_to_anchor=(0.5,-0.43),\n",
    "        ncol=3,\n",
    "        labels = values_cat\n",
    "    )\n",
    "    fig.tight_layout()\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
